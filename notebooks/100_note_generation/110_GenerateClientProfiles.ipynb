{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/olympia/notebooks/100_note_generation/110_GenerateClientProfiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JX5RYxDmQNj"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/notebooks/100_note_generation/110_GenerateClientProfiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKGyZin9teK"
      },
      "source": [
        "# GenCare AI: Generating client profiles\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:** 2024-06-01  \n",
        "**Updated:** 2024-09-29  \n",
        "**Version:** 2.0\n",
        "\n",
        "### Description\n",
        "This script generates synthetic healthcare data, used as testing material for NLP experiments. It generates client profiles for a psychogeriatric ward using the OpenAI GPT-4 model.\n",
        "\n",
        "The output parser uses a structure called ClientProfile, which is created with Pydantic models. Pydantic helps define and validate the output for each client profile, ensuring that each profile has the right format and contains the necessary information.\n",
        "\n",
        "With the current settings of generating eight profiles per query and running the query three times, the cost is approximately $0.05 per run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CShB1ZlNBXJL"
      },
      "outputs": [],
      "source": [
        "!pip install GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "        !pip install -q langchain langchain_core langchain_openai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qke9UwhUFE5z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.callbacks import get_openai_callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U8-agi-oC9w"
      },
      "outputs": [],
      "source": [
        "# Constants and Configurations\n",
        "# The ward name will be used in the filename. Practical when performing multiple\n",
        "# experiments\n",
        "WARD_NAME = 'Hermes'\n",
        "FN_PROFILES =  setup.get_file_path(f'data/gcai_client_profiles_{WARD_NAME}.csv')\n",
        "# Per query eight profiles are generated. The query is run NUM_WINGS times, so\n",
        "# when NUM_WINGS is set to 3 the total number of client profiles generated is 24.\n",
        "NUM_WINGS = 3\n",
        "# GPT-4o yields better, more diverse results than gpt-3.5\n",
        "MODEL_PROFILES = 'gpt-4o-2024-05-13'\n",
        "TEMP = 1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quwsQty8j5Fo"
      },
      "outputs": [],
      "source": [
        "# Definition of Pydantic model to structure the client profile data\n",
        "class ClientProfile(BaseModel):\n",
        "    naam: str = Field(description=\"naam van de client (Meneer/Mevrouw Voornaam Achternaam, gebruik een naam die je normaal niet zou kiezen)\")\n",
        "    type_dementie: str = Field(description=\"type dementie (Alzheimer, gemengde dementie, vasculaire dementie, lewy body dementie, parkinsondementie, FTD: varieer, de kans op Alzheimer, gemengde en vasculaire dementie is het grootst)\")\n",
        "    somatiek: str = Field(description=\"lichamelijke klachten\")\n",
        "    # biografie: str = Field(description=\"een korte beschrijving van karakter en relevante biografische gegevens (vermijd stereotypen in beroep en achtergrond)\")\n",
        "    adl: str = Field(description=\"beschrijf welke ADL hulp de cliënt nodig heeft\")\n",
        "    mobiliteit: str = Field(description=\"beschrijf de mobiliteit (bv rolstoelafhankelijk, gebruik rollator, valgevaar)\")\n",
        "    gedrag: str = Field(description=\"beschrijf voor de zorg relevante aspecten van cognitie en probleemgedrag. Varieer met de ernst van het probleemgedrag van rustige cliënten, gemiddeld onrustige cliënten tot cliënten die fors apathisch, onrustig, angstig, geagiteerd of zelfs agressief kunnen zijn\")\n",
        "\n",
        "# Pydantic model to hold multiple client profiles\n",
        "class ClientProfiles(BaseModel):\n",
        "    clients: List[ClientProfile]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1sD0rHaBXJP"
      },
      "outputs": [],
      "source": [
        "# Initialize OpenAI model and parser\n",
        "model= ChatOpenAI(api_key=setup.get_openai_key(), temperature=TEMP, model=MODEL_PROFILES)\n",
        "pyd_parser = PydanticOutputParser(pydantic_object=ClientProfiles)\n",
        "format_instructions = pyd_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0eCENdbBXJQ"
      },
      "outputs": [],
      "source": [
        "PT_client_profiles = PromptTemplate(\n",
        "    template = \"\"\"\n",
        "Schrijf acht profielen van cliënten die zijn opgenomen op een psychogeriatrische afdeling van het verpleeghuis. Hier wonen mensen met een gevorderde dementie met een hoge zorgzwaarte.\n",
        "Zorg dat de profielen erg van elkaar verschillen.\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\",\n",
        "    input_variables=[],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "P_client_profiles = PT_client_profiles.format(profile=\"profile\", scenario=\"scenario\")\n",
        "print(P_client_profiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGNE_YokmQNq"
      },
      "outputs": [],
      "source": [
        "# Combine the prompt, model, and parser into a single chain\n",
        "chain_client_profiles = PT_client_profiles | model | pyd_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNu7vcqmQNq"
      },
      "outputs": [],
      "source": [
        "# Generate and save data\n",
        "if not os.path.exists(FN_PROFILES):\n",
        "    print(\"Data file not found. Generating new data...\")\n",
        "\n",
        "    os.makedirs(os.path.dirname(FN_PROFILES), exist_ok=True)\n",
        "\n",
        "    def generate_data():\n",
        "        all_data = []\n",
        "        for i in range(NUM_WINGS):\n",
        "            print(f'Generating data for wing {i+1}')\n",
        "            result = chain_client_profiles.invoke({})\n",
        "            if result is None or not hasattr(result, 'clients'):\n",
        "                raise ValueError(\"No valid response received from the model.\")\n",
        "            data = [client.dict() for client in result.clients]\n",
        "            all_data.extend(data)\n",
        "        return pd.DataFrame(all_data)\n",
        "\n",
        "    def add_client_id(df):\n",
        "        df['client_id'] = range(1, len(df) + 1)\n",
        "        return df[['client_id', 'naam', 'type_dementie', 'somatiek', 'adl', 'mobiliteit', 'gedrag']]\n",
        "\n",
        "    with get_openai_callback() as cb:\n",
        "        df = generate_data()\n",
        "        print(\"Data generated successfully.\\n\")\n",
        "        print(cb)\n",
        "\n",
        "    df_with_id = add_client_id(df)\n",
        "    df_with_id.to_csv(FN_PROFILES, index=False)\n",
        "    print(f\"Data saved successfully to {FN_PROFILES}.\")\n",
        "else:\n",
        "    print(\"Data file found. Loading data...\")\n",
        "    df_with_id = pd.read_csv(FN_PROFILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajVXypknmQNq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}