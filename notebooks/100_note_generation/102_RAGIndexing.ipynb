{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/olympia/notebooks/100_note_generation/112_RAGIndexing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_63aAoRXj07"
      },
      "source": [
        "# GenCare AI: Retrieval Augmented Generation of care notes\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:** 2024-06-03  \n",
        "**Updated:** 2024-09-30  \n",
        "**Version:** 2.0\n",
        "\n",
        "### Description\n",
        "In the previous notebook, we generated progress notes for nursing home residents using a GPT model. In this notebook, we will create a vector database to store these progress notes, which will later be used as few-shot examples for generating new client records.\n",
        "\n",
        "The workflow includes loading a dataset of care notes, splitting these notes into manageable chunks, and embedding them using OpenAIâ€™s text-embedding-ada-002 model. These embeddings are stored in a Chroma vector database.\n",
        "\n",
        "- Documents can be loaded either from a csv file or from HuggingFace.\n",
        "- The notes are split into smaller chunks, even though this probably was not necessary for this dataset. This step was taken for completeness to ensure scalability in the future.  \n",
        "- When running in CoLab Google Drive is mounted to persistently store the Chroma vector database.\n",
        "- Retrieve API keys for OpenAI and HuggingFace, providing authentication for accessing the [embedding model](https://platform.openai.com/docs/guides/embeddings), the [QA model](https://platform.openai.com/docs/models) and the [dataset](https://huggingface.co/datasets/ekrombouts/Gardenia_notes).\n",
        "\n",
        "### Recommended Resources\n",
        "- [RAG - Retrieval Augmented Generation](https://www.youtube.com/playlist?list=PL8motc6AQftn-X1HkaGG9KjmKtWImCKJS) with Sam Witteveen on YouTube\n",
        "- [Python RAG Tutorial (with Local LLMs)](https://www.youtube.com/watch?v=2TJxpyO3ei4&t=323s) by Pixegami on YouTube\n",
        "- And of course the [Langchain documentation](https://python.langchain.com/v0.1/docs/use_cases/question_answering/)\n",
        "\n",
        "***Please note*** that the embedding isn't free. Embedding the 35.000+ notes costs appr $0.15. The costs for the examples of querying the database in this notebook are negligible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-ciQB-KPOhw"
      },
      "outputs": [],
      "source": [
        "!pip install GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "        !pip install -q langchain langchain-openai langchain-community chromadb datasets langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nxPS7wYjrugf"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules from Langchain and Hugging Face\n",
        "import os\n",
        "import pandas as pd\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "from langchain_community.document_loaders import HuggingFaceDatasetLoader, DataFrameLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema.document import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YCGSQTBMrzxT"
      },
      "outputs": [],
      "source": [
        "# Constants for dataset and storage paths\n",
        "# Use local csv or HuggingFace dataset\n",
        "# path_dataset = setup.get_file_path('data/gcai_notes.csv')\n",
        "path_dataset = \"ekrombouts/Gardenia_notes\"\n",
        "\n",
        "path_db_gcai = setup.get_file_path('data/chroma_db_gcai')\n",
        "collection_name = 'Gardenia'\n",
        "model = 'text-embedding-ada-002'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l29SPKZNsfuN"
      },
      "outputs": [],
      "source": [
        "def load_documents(path):\n",
        "    \"\"\"Load the dataset either from Hugging Face or a local CSV file based on the path provided.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Try to load the Hugging Face dataset\n",
        "        loader = HuggingFaceDatasetLoader(path=path,\n",
        "                                          page_content_column='note',\n",
        "                                          # use_auth_token=setup.get_hf_token()\n",
        "                                          )\n",
        "        return loader.load()\n",
        "\n",
        "    except Exception as e:\n",
        "        # If loading as a Hugging Face dataset fails, assume it's a CSV file\n",
        "        df = pd.read_csv(path)\n",
        "        loader = DataFrameLoader(df, page_content_column='note')\n",
        "        return loader.load()\n",
        "\n",
        "documents = load_documents(path=path_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCRJwVFXuyE9"
      },
      "outputs": [],
      "source": [
        "def split_documents(documents: list[Document]):\n",
        "  \"\"\"Split large text documents into manageable chunks for better handling by ML models.\"\"\"\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=800,\n",
        "      chunk_overlap=100)\n",
        "  chunks = text_splitter.split_documents(documents)\n",
        "  # Index each chunk to maintain unique identifiers\n",
        "  for idx, chunk in enumerate(chunks):\n",
        "      chunk.metadata['id'] = str(idx)\n",
        "  return chunks\n",
        "\n",
        "chunks = split_documents(documents=documents)\n",
        "\n",
        "print(len(documents))\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZKYyBXp7iTp"
      },
      "outputs": [],
      "source": [
        "def initialize_vectordb(persist_directory, embedding_function, collection_name):\n",
        "    \"\"\"Initialize the Chroma vector database, either loading an existing one or creating a new one.\"\"\"\n",
        "    if os.path.exists(persist_directory):\n",
        "        return Chroma(persist_directory=persist_directory,\n",
        "                      embedding_function=embedding_function,\n",
        "                      collection_name=collection_name)\n",
        "    else:\n",
        "        return Chroma(embedding_function=embedding_function,\n",
        "                      persist_directory=persist_directory,\n",
        "                      collection_name=collection_name)\n",
        "\n",
        "# Initialize vector database, using OpenAI embeddings\n",
        "embedding = OpenAIEmbeddings(api_key=setup.get_openai_key(), model=model)\n",
        "vectordb = initialize_vectordb(path_db_gcai, embedding, collection_name)\n",
        "\n",
        "# If you get an error, run this cell again.(TODO fix it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AyU-sUcPOhz"
      },
      "outputs": [],
      "source": [
        "# Modified from https://github.com/pixegami/rag-tutorial-v2/blob/main/populate_database.py\n",
        "def add_new_documents(vectordb, documents, batch_size=5000):\n",
        "    \"\"\"Add new documents to the database\"\"\"\n",
        "\n",
        "    def load_existing_ids(vectordb):\n",
        "        \"\"\"Fetch existing document IDs from the database to avoid duplicates.\"\"\"\n",
        "        try:\n",
        "            existing_items = vectordb.get(include=[])\n",
        "            existing_ids = set(existing_items[\"ids\"])\n",
        "        except:\n",
        "            existing_ids = set()\n",
        "        return existing_ids\n",
        "\n",
        "    existing_ids = load_existing_ids(vectordb)\n",
        "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
        "\n",
        "    # Only add documents that don't exist in the DB.\n",
        "    new_documents = []\n",
        "    for document in documents:\n",
        "        if document.metadata[\"id\"] not in existing_ids:\n",
        "            new_documents.append(document)\n",
        "\n",
        "    if len(new_documents):\n",
        "        print(f\"Total new documents to add: {len(new_documents)}\")\n",
        "\n",
        "        # Process documents in batches\n",
        "        for i in range(0, len(new_documents), batch_size):\n",
        "            batch = new_documents[i:i + batch_size]\n",
        "            batch_ids = [document.metadata[\"id\"] for document in batch]\n",
        "            vectordb.add_documents(batch, ids=batch_ids)\n",
        "            print(f\"Added batch {i//batch_size + 1} with {len(batch)} documents\")\n",
        "    else:\n",
        "        print(\"No new documents to add\")\n",
        "\n",
        "add_new_documents(vectordb, chunks, batch_size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_PgSt42POh1"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
