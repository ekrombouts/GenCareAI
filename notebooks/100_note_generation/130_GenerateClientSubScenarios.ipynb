{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/olympia/notebooks/100_note_generation/120_GenerateClientScenarios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKGyZin9teK"
      },
      "source": [
        "# GenCare AI: Generating subscenarios\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:**   02-10-2024  \n",
        "**Updated:**   \n",
        "**Version:** 0.1\n",
        "\n",
        "### Description\n",
        "This notebook generates detailed subscenarios for clients in a nursing home setting based on their profiles and main scenarios. The subscenarios are derived by dividing each period in the main scenario into four shorter periods, each representing a week of care for the client. The output is intended for use in fictive care reports.\n",
        "\n",
        "The script uses a pre-defined client profile and main scenario as input, processes them through a language model, and outputs a list of subscenarios. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCvrV851kxQM"
      },
      "outputs": [],
      "source": [
        "!pip install GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "        !pip install -q langchain langchain_core langchain_openai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qke9UwhUFE5z"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6U8-agi-oC9w"
      },
      "outputs": [],
      "source": [
        "# Constants and Configurations\n",
        "ward_name = 'Athena'\n",
        "fn_profiles = setup.get_file_path(f'data/gcai_client_profiles_{ward_name}.csv')\n",
        "fn_scenarios = setup.get_file_path(f'data/gcai_client_scenarios_{ward_name}.csv')\n",
        "fn_subscenarios = setup.get_file_path(f'data/gcai_client_subscenarios_{ward_name}.csv')\n",
        "fn_raw_results = setup.get_file_path('data/raw_results.pkl')\n",
        "\n",
        "# model = 'gpt-4o-mini-2024-07-18'\n",
        "model = 'gpt-3.5-turbo-0125'\n",
        "temp = 1.1\n",
        "\n",
        "verbose = False\n",
        "sample_client = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ooVq9oALSwXa"
      },
      "outputs": [],
      "source": [
        "# Load the client profiles\n",
        "df_scenarios = pd.read_csv(fn_scenarios)\n",
        "df_profiles = pd.read_csv(fn_profiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_profiles.info()\n",
        "df_scenarios.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-ugZRr6Oarb5"
      },
      "outputs": [],
      "source": [
        "# Pydantic models\n",
        "class ClientSubScenario(BaseModel):\n",
        "    period: int = Field(description=\"Volgnummer van de periode\")\n",
        "    sub_period: int = Field(description=\"Volgnummer van de sub-periode\")\n",
        "    events_description: str = Field(description=\"Beschrijving van de gebeurtenissen en zorg\")\n",
        "\n",
        "class ClientSubScenarios(BaseModel):\n",
        "    scenario: List[ClientSubScenario]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XJUm3Dtwz3Rv"
      },
      "outputs": [],
      "source": [
        "# Initialize model and parser\n",
        "model = ChatOpenAI(api_key=setup.get_openai_key(), temperature=temp, model=model)\n",
        "pyd_parser = PydanticOutputParser(pydantic_object=ClientSubScenarios)\n",
        "format_instructions = pyd_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_profile(row):\n",
        "    # Format the client's profile for display\n",
        "    return (\n",
        "        f\"Naam: {row['naam']}\\n\"\n",
        "        f\"Type Dementie: {row['type_dementie']}\\n\"\n",
        "        f\"Lichamelijke klachten: {row['somatiek']}\\n\"\n",
        "        f\"ADL: {row['adl']}\\n\"\n",
        "        f\"Mobiliteit: {row['mobiliteit']}\\n\"\n",
        "        f\"Cognitie/gedrag: {row['gedrag']}\"\n",
        "    )\n",
        "\n",
        "if verbose:\n",
        "    sample_profile = display_profile(df_profiles.iloc[sample_client])\n",
        "    print(sample_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_scenario(row, df_scenarios):\n",
        "    # Format the client's scenario for display\n",
        "    client_id = row['client_id']\n",
        "    return (\"\\n\".join(f\"{r['period']}: {r['events_description']}\" for index, r in df_scenarios[df_scenarios['client_id'] == client_id].iterrows()))\n",
        "\n",
        "if verbose:\n",
        "    sample_scenario = display_scenario(df_profiles.iloc[sample_client], df_scenarios=df_scenarios)\n",
        "    print(sample_scenario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TOxQDCbfF1FH"
      },
      "outputs": [],
      "source": [
        "# Define the prompt template\n",
        "template=\"\"\"\n",
        "Help me bij het schrijven van een scenario van een fictieve client die is opgenomen in het verpleeghuis. Deze client is ernstig beperkt, vanwege een dementie of vanwege onderliggend lichamelijk lijden. Het scenario speelt zich af in het verpleeghuis, dus over het algemeen kabbelt de zorg rustig door. Vermijd dramatiek. Vermijd het noemen van de naam. Maak de wijzigingen subtieler dan je normaal zou doen.\n",
        "\n",
        "OPDRACHT: Schrijf een scenario van onderstaand profiel en hoofdscenario, waarbij je elke periode uit het hoofdscenario opdeelt in 4 kortere perioden (subscenario's) die elk een week van de client in het verpleeghuis beschrijven. Deze scenario's zullen later worden gebruikt om fictieve zorgrapportages te schrijven. \n",
        "\n",
        "PROFIEL\n",
        "{client_profile}\n",
        "\n",
        "HOOFDSCENARIO\n",
        "{scenario}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"client_profile\", \"scenario\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "if verbose:\n",
        "    print(prompt_template.format(client_profile=sample_profile,\n",
        "                                 scenario = sample_scenario))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NdHaBX_taktA"
      },
      "outputs": [],
      "source": [
        "# Create a chain\n",
        "chain = prompt_template | model | pyd_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "if verbose: \n",
        "    with get_openai_callback() as cb:\n",
        "        result = chain.invoke({\"client_profile\": sample_profile, \"scenario\": sample_scenario})\n",
        "    print(cb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if verbose:\n",
        "#     print(result.scenario[0].events_description)\n",
        "#     # print(type(result))\n",
        "#     print(100*'*')\n",
        "#     # print(vars(result))\n",
        "#     # print(100*'*')\n",
        "#     print(result.scenario)\n",
        "\n",
        "result.scenario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_QL3H8iz3Rv"
      },
      "outputs": [],
      "source": [
        "# Generate and save subscenarios\n",
        "if not os.path.exists(fn_subscenarios):\n",
        "    print(\"Data file not found. Generating new data...\")\n",
        "\n",
        "    def generate_subscenarios(df_profiles, df_scenarios, chain):\n",
        "        subscenario_list = []\n",
        "        raw_results_list = []  \n",
        "        for _, row in df_profiles.iterrows():\n",
        "            client_profile = display_profile(row=row)\n",
        "            client_scenario = display_scenario(row=row, df_scenarios=df_scenarios)\n",
        "            print(f\"Generating detailed scenario for client: {row['naam']}\")\n",
        "\n",
        "            try:\n",
        "                result = chain.invoke({\"client_profile\": client_profile, \"scenario\": client_scenario})\n",
        "            except Exception as e:\n",
        "                print(f\"Error encountered: {e}. Retrying...\")\n",
        "                result = chain.invoke({\"client_profile\": client_profile, \"scenario\": client_scenario})\n",
        "                print(\"Retry successful\")\n",
        "            raw_results_list.append(result)\n",
        "\n",
        "            for scenario in result.scenario:\n",
        "                subscenario_list.append((row['client_id'], scenario.period, scenario.sub_period, scenario.events_description))\n",
        "        return subscenario_list, raw_results_list\n",
        "\n",
        "    with get_openai_callback() as cb:\n",
        "        subscenario_data, raw_results_data = generate_subscenarios(\n",
        "            df_profiles=df_profiles,\n",
        "            df_scenarios=df_scenarios,\n",
        "            chain=chain\n",
        "        )\n",
        "        print(cb)\n",
        "\n",
        "    # Save the generated subscenarios\n",
        "    df_subscenarios = pd.DataFrame(\n",
        "        subscenario_data, \n",
        "        columns=['client_id', 'period', 'sub_period', 'events_description']\n",
        "    )\n",
        "    df_subscenarios.to_csv(fn_subscenarios, index=False)\n",
        "    print(f\"Data saved successfully to {fn_scenarios}.\")\n",
        "\n",
        "    # Save raw results\n",
        "    with open(fn_raw_results, 'wb') as f:\n",
        "        pickle.dump(raw_results_data, f)\n",
        "    print(f\"Raw results saved successfully to {fn_raw_results}.\")\n",
        "\n",
        "else:\n",
        "    print(\"Data file found. Loading data...\")\n",
        "    df_subscenarios = pd.read_csv(fn_subscenarios)\n",
        "    with open(fn_raw_results, 'rb') as f:\n",
        "        raw_results_data = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_results_data[0].scenario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_period_number(period_str):\n",
        "    period_str = str(period_str).lower()\n",
        "    \n",
        "    # Words to numbers mapping\n",
        "    word_to_num = {\n",
        "        'eerste': 1,\n",
        "        'tweede': 2,\n",
        "        'derde': 3,\n",
        "        'vierde': 4,\n",
        "        'vijfde': 5,\n",
        "        'zesde': 6,\n",
        "        'zevende': 7,\n",
        "        'achtste': 8,\n",
        "        'negende': 9,\n",
        "        'tiende': 10,\n",
        "    }\n",
        "    \n",
        "    match = re.search(r'\\d+', period_str)\n",
        "    if match:\n",
        "        return int(match.group())\n",
        "    else:\n",
        "        for word, num in word_to_num.items():\n",
        "            if word in period_str:\n",
        "                return num\n",
        "    return None\n",
        "\n",
        "# Add numeric period numbers to the DataFrames\n",
        "df_scenarios['period_num'] = df_scenarios['period'].apply(extract_period_number)\n",
        "df_subscenarios['period_num'] = df_subscenarios['period'].astype(int)\n",
        "\n",
        "# Count subscenarios per client and period\n",
        "subscenario_counts = df_subscenarios.groupby(['client_id', 'period_num']).size().reset_index(name='subscenario_count')\n",
        "\n",
        "# Merge counts with the original scenarios DataFrame\n",
        "df_merged = pd.merge(df_scenarios, subscenario_counts, on=['client_id', 'period_num'], how='left')\n",
        "df_merged['subscenario_count'] = df_merged['subscenario_count'].fillna(0).astype(int)\n",
        "\n",
        "# Check for periods that do not have exactly 4 subscenarios\n",
        "incorrect_counts = df_merged[df_merged['subscenario_count'] != 4]\n",
        "\n",
        "if incorrect_counts.empty:\n",
        "    print(\"Alle periodes hebben precies 4 subscenario's in df_subscenarios.\")\n",
        "else:\n",
        "    print(\"De volgende periodes hebben geen 4 subscenario's:\")\n",
        "    print(incorrect_counts[['client_id', 'period', 'subscenario_count']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_subscenarios['client_id'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
