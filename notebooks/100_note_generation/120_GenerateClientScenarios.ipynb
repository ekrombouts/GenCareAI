{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/notebooks/100_note_generation/120_GenerateClientScenarios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKGyZin9teK"
      },
      "source": [
        "# GenCare AI: Generating client scenarios\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:**   13-06-2024  \n",
        "**Updated:** 2024-09-01  \n",
        "**Version:** 1.2\n",
        "\n",
        "### Description\n",
        "This scripts generates client scenarios based on profiles generated [here](https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/notebooks/100_note_generation/110_GenerateClientProfiles.ipynb).\n",
        "\n",
        "Generating scenarios based on 24 client profiles and 8 months, the cost is approximately $0.03 per run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VCvrV851kxQM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: GenCareAI in /Users/eva/anaconda3/envs/gcai/lib/python3.10/site-packages (0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "        !pip install -q langchain langchain_core langchain_openai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qke9UwhUFE5z"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6U8-agi-oC9w"
      },
      "outputs": [],
      "source": [
        "# Constants and Configurations\n",
        "WARD_NAME = 'Athena'\n",
        "FN_PROFILES = setup.get_file_path(f'data/gcai_client_profiles_{WARD_NAME}.csv')\n",
        "FN_SCENARIOS = setup.get_file_path(f'data/gcai_client_scenarios_{WARD_NAME}.csv')\n",
        "\n",
        "MODEL_SCENARIOS = 'gpt-3.5-turbo-0125'\n",
        "TEMP = 1.1\n",
        "\n",
        "DURATION = 8 # Number of 'months' or periods\n",
        "DURATION_SD = 3 # Standard deviation of the number of months\n",
        "NUM_COMPLICATIONS_MIN = 1\n",
        "NUM_COMPLICATIONS_MAX = 3\n",
        "\n",
        "complications_library = [\"gewichtsverlies\", \"algehele achteruitgang\", \"decubitus\", \"urineweginfectie\", \"pneumonie\", \"delier\", \"verergering van onderliggende lichamelijke klachten\", \"verbetering van de klachten\", \"overlijden\", \"valpartij\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ooVq9oALSwXa"
      },
      "outputs": [],
      "source": [
        "# Load the client profiles\n",
        "df = pd.read_csv(FN_PROFILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-ugZRr6Oarb5"
      },
      "outputs": [],
      "source": [
        "# Pydantic models\n",
        "class ClientScenario(BaseModel):\n",
        "    month: str = Field(description=\"Volgnummer van de maand\")\n",
        "    journey: str = Field(description=\"Beschrijving van de gebeurtenissen en zorg\")\n",
        "\n",
        "class ClientScenarios(BaseModel):\n",
        "    scenario: List[ClientScenario]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model and parser\n",
        "model = ChatOpenAI(api_key=setup.get_openai_key(), temperature=TEMP, model=MODEL_SCENARIOS)\n",
        "pyd_parser = PydanticOutputParser(pydantic_object=ClientScenarios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TOxQDCbfF1FH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dit is het profiel van een fictieve client in het verpleeghuis:\n",
            "---\n",
            "client profiel\n",
            "---\n",
            "\n",
            "Schrijf in een tijdlijn het beloop van zijn/haar verblijf in het verpleeghuis gedurende 6 maanden.\n",
            "Verwerk de volgende complicatie(s) hierin: complicatie(s).\n",
            "Hou wijzigingen subtiel. Vermijd al te grote dramatiek.\n",
            "Vermijd het noemen van de naam.\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"scenario\": {\"title\": \"Scenario\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/ClientScenario\"}}}, \"required\": [\"scenario\"], \"definitions\": {\"ClientScenario\": {\"title\": \"ClientScenario\", \"type\": \"object\", \"properties\": {\"month\": {\"title\": \"Month\", \"description\": \"Volgnummer van de maand\", \"type\": \"string\"}, \"journey\": {\"title\": \"Journey\", \"description\": \"Beschrijving van de gebeurtenissen en zorg\", \"type\": \"string\"}}, \"required\": [\"month\", \"journey\"]}}}\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt template\n",
        "PT_scenario = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Dit is het profiel van een fictieve client in het verpleeghuis:\n",
        "---\n",
        "{client_profile}\n",
        "---\n",
        "\n",
        "Schrijf in een tijdlijn het beloop van zijn/haar verblijf in het verpleeghuis gedurende {num_months} maanden.\n",
        "Verwerk de volgende complicatie(s) hierin: {complications}.\n",
        "Hou wijzigingen subtiel. Vermijd al te grote dramatiek.\n",
        "Vermijd het noemen van de naam.\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\",\n",
        "    input_variables=[\"client_profile\", \"num_months\", \"complications\"],\n",
        "    partial_variables={\"format_instructions\": pyd_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "P_scenario = PT_scenario.format(client_profile=\"client profiel\",\n",
        "                                      num_months = 6,\n",
        "                                      complications = \"complicatie(s)\")\n",
        "print(P_scenario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NdHaBX_taktA"
      },
      "outputs": [],
      "source": [
        "# Create a chain of operations: prompt template -> model -> output parser\n",
        "chain_scenario = PT_scenario | model | pyd_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data file not found. Generating new data...\n",
            "Generating scenario for client: Meneer Johan van der Vliet\n",
            "Generating scenario for client: Mevrouw Erica Groenhof\n",
            "Generating scenario for client: Meneer Arnold Bergkamp\n",
            "Generating scenario for client: Mevrouw Vera Verhagen\n",
            "Generating scenario for client: Meneer Kees de Punder\n",
            "Generating scenario for client: Mevrouw Hannelore Klaassen\n",
            "Generating scenario for client: Meneer Roel Hulshof\n",
            "Generating scenario for client: Mevrouw Bianca te Boekhorst\n",
            "Tokens Used: 7258\n",
            "\tPrompt Tokens: 3892\n",
            "\tCompletion Tokens: 3366\n",
            "Successful Requests: 8\n",
            "Total Cost (USD): $0.006995000000000001\n",
            "Data saved successfully to /Users/eva/Library/CloudStorage/GoogleDrive-e.k.rombouts@gmail.com/My Drive/Colab Notebooks/GenCareAI/data/gcai_client_scenarios_Athena.csv.\n"
          ]
        }
      ],
      "source": [
        "# Generate and save scenarios\n",
        "if not os.path.exists(FN_SCENARIOS):\n",
        "    print(\"Data file not found. Generating new data...\")\n",
        "\n",
        "    def generate_scenarios(df, chain):\n",
        "        def display_profile(row):\n",
        "            return (\n",
        "                f\"Naam: {row['naam']}\\n\"\n",
        "                f\"Type Dementie: {row['type_dementie']}\\n\"\n",
        "                f\"Lichamelijke klachten: {row['somatiek']}\\n\"\n",
        "                f\"ADL: {row['adl']}\\n\"\n",
        "                f\"Mobiliteit: {row['mobiliteit']}\\n\"\n",
        "                f\"Cognitie / gedrag: {row['gedrag']}\"\n",
        "            )\n",
        "\n",
        "        def determine_duration(mean=6, std_dev=2):\n",
        "            return int(np.round(np.random.normal(mean, std_dev)))\n",
        "\n",
        "        def determine_num_complications(min=1, max=3):\n",
        "            return random.randint(min, max)\n",
        "\n",
        "        scenario_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            client_profile = display_profile(row)\n",
        "            print(f\"Generating scenario for client: {row['naam']}\")\n",
        "            num_months = determine_duration(mean=DURATION, std_dev=DURATION_SD)\n",
        "            num_complications = determine_num_complications(min=NUM_COMPLICATIONS_MIN, max=NUM_COMPLICATIONS_MAX)\n",
        "            chosen_complications = random.sample(complications_library, num_complications)\n",
        "            complications = \", \".join(chosen_complications)\n",
        "            result = chain.invoke({\"client_profile\": client_profile, \"num_months\": str(num_months), \"complications\": complications})\n",
        "            for scenario in result.scenario:\n",
        "                scenario_list.append((row['client_id'], scenario.month, scenario.journey, complications, num_months))\n",
        "        return scenario_list\n",
        "\n",
        "    with get_openai_callback() as cb:\n",
        "        scenario_data = generate_scenarios(df, chain_scenario)\n",
        "        print(cb)\n",
        "\n",
        "    df_scenarios = pd.DataFrame(scenario_data, columns=['client_id', 'month', 'journey', 'complications', 'num_months'])\n",
        "    df_scenarios.to_csv(FN_SCENARIOS, index=False)\n",
        "    print(f\"Data saved successfully to {FN_SCENARIOS}.\")\n",
        "else:\n",
        "    print(\"Data file found. Loading data...\")\n",
        "    df_scenarios = pd.read_csv(FN_SCENARIOS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
