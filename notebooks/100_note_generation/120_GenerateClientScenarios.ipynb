{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/scripts/100_note_generation/120_GenerateClientScenarios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKGyZin9teK"
      },
      "source": [
        "# GenCare AI: Generating client scenarios\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:**   13-06-2024  \n",
        "**Updated:** 2024-07-01  \n",
        "**Version:** 1.1\n",
        "\n",
        "### Description\n",
        "This scripts generates client scenarios based on profiles generated [here](https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/scripts/110_GenerateClientProfiles.ipynb).\n",
        "\n",
        "Version 1.1: Minor changes. Added constants for duration & num_complications\n",
        "\n",
        "Generating scenarios based on 24 client profiles and 8 months, the cost is approximately $0.03 per run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU6QkqygkxQM"
      },
      "source": [
        "### Imports and constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCvrV851kxQM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Determines the current environment (Google Colab or local)\n",
        "def check_environment():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return \"Google Colab\"\n",
        "    except ImportError:\n",
        "        pass\n",
        "\n",
        "    return \"Local Environment\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKOi1LkokxQN"
      },
      "outputs": [],
      "source": [
        "# Installs and settings depending on the environment\n",
        "# When running in CoLab, the Google drive is mounted and necessary packages are installed.\n",
        "# Data paths are set and API keys retrieved\n",
        "\n",
        "env = check_environment()\n",
        "\n",
        "if env == \"Google Colab\":\n",
        "    print(\"Running in Google Colab\")\n",
        "    !pip install -q langchain langchain_core langchain_openai langchain_community\n",
        "    from google.colab import drive, userdata\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir('/content/drive/My Drive/Colab Notebooks/GenCareAI/scripts')\n",
        "    OPENAI_API_KEY = userdata.get('GCI_OPENAI_API_KEY')\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "else:\n",
        "    print(\"Running in Local Environment\")\n",
        "    # !pip install -q\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "    OPENAI_API_KEY = os.getenv('GCI_OPENAI_API_KEY')\n",
        "    HF_TOKEN = os.getenv('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qke9UwhUFE5z"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U8-agi-oC9w"
      },
      "outputs": [],
      "source": [
        "# Constants and Configurations\n",
        "WARD_NAME = 'Aurora'\n",
        "FN_PROFILES = f'../../data/gcai_client_profiles_{WARD_NAME}.csv'\n",
        "FN_SCENARIOS = f'../../data/gcai_client_scenarios_{WARD_NAME}.csv'\n",
        "\n",
        "MODEL_SCENARIOS = 'gpt-3.5-turbo-0125'\n",
        "TEMP = 1.1\n",
        "\n",
        "DURATION = 8 # Number of 'months' or periods\n",
        "DURATION_SD = 3 # Standard deviation of the number of months\n",
        "NUM_COMPLICATIONS_MIN = 1\n",
        "NUM_COMPLICATIONS_MAX = 3\n",
        "\n",
        "complications_library = [\"gewichtsverlies\", \"algehele achteruitgang\", \"decubitus\", \"urineweginfectie\", \"pneumonie\", \"delier\", \"verergering van onderliggende lichamelijke klachten\", \"verbetering van de klachten\", \"overlijden\", \"valpartij\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrsECFfukxQN"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooVq9oALSwXa"
      },
      "outputs": [],
      "source": [
        "# Load the client profiles\n",
        "df = pd.read_csv(FN_PROFILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ugZRr6Oarb5"
      },
      "outputs": [],
      "source": [
        "# Pydantic models\n",
        "class ClientScenario(BaseModel):\n",
        "    month: str = Field(description=\"Volgnummer van de maand\")\n",
        "    journey: str = Field(description=\"Beschrijving van de gebeurtenissen en zorg\")\n",
        "\n",
        "class ClientScenarios(BaseModel):\n",
        "    scenario: List[ClientScenario]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FLgZm2rkxQO"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xJt-dTtTHtl"
      },
      "outputs": [],
      "source": [
        "def display_profile(row):\n",
        "    profile = (\n",
        "        f\"Naam: {row['naam']}\\n\"\n",
        "        f\"Type Dementie: {row['type_dementie']}\\n\"\n",
        "        f\"Lichamelijke klachten: {row['somatiek']}\\n\"\n",
        "        f\"ADL: {row['adl']}\\n\"\n",
        "        f\"Mobiliteit: {row['mobiliteit']}\\n\"\n",
        "        f\"Cognitie / gedrag: {row['gedrag']}\"\n",
        "    )\n",
        "    return profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wy0zGh1kMfe"
      },
      "outputs": [],
      "source": [
        "# Function to determine the number of months of the scenario\n",
        "def determine_duration(mean=6, std_dev=2):\n",
        "    return int(np.round(np.random.normal(mean, std_dev)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def determine_num_complications(min=1, max=3):\n",
        "    return random.randint(min, max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Fjn5zzckxQO"
      },
      "outputs": [],
      "source": [
        "def generate_scenarios(df, chain):\n",
        "    scenario_list = []\n",
        "    for _, row in df.iterrows():\n",
        "        client_profile = display_profile(row)\n",
        "        print(f\"Generating scenario for client: {row['naam']}\")\n",
        "        num_months = determine_duration(mean=DURATION, std_dev=DURATION_SD)\n",
        "        num_complications = determine_num_complications(min=NUM_COMPLICATIONS_MIN, max=NUM_COMPLICATIONS_MAX)\n",
        "        chosen_complications = random.sample(complications_library, num_complications)\n",
        "        complications = \", \".join(chosen_complications)\n",
        "        result = chain.invoke({\"client_profile\": client_profile, \"num_months\": str(num_months), \"complications\": complications})\n",
        "        for scenario in result.scenario:\n",
        "            scenario_list.append((row['client_id'], scenario.month, scenario.journey, complications, num_months))\n",
        "    return scenario_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HRjYdgwkxQO"
      },
      "outputs": [],
      "source": [
        "def save_data(df, file_path):\n",
        "    print(f\"Data saved successfully to {file_path}.\")\n",
        "    df.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcnl1PEokxQO"
      },
      "outputs": [],
      "source": [
        "def main(df, chain, file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        print(\"Data file found. Loading data...\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"Data file not found. Generating new data...\")\n",
        "        with get_openai_callback() as cb:\n",
        "            scenario_data = generate_scenarios(df, chain)\n",
        "            print(cb)\n",
        "        df_scenarios = pd.DataFrame(scenario_data, columns=['client_id', 'month', 'journey', 'complications', 'num_months'])\n",
        "        save_data(df_scenarios, file_path)\n",
        "        return df_scenarios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg-MlfW-kxQO"
      },
      "source": [
        "### Model initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "# Initialize OpenAI Chat model\n",
        "model = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=TEMP, model=MODEL_SCENARIOS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjFgTPeXZ46j"
      },
      "outputs": [],
      "source": [
        "# Set up a parser to handle the output and inject instructions into the prompt template\n",
        "pyd_parser = PydanticOutputParser(pydantic_object=ClientScenarios)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GarNY0dkxQO"
      },
      "source": [
        "### Prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOxQDCbfF1FH"
      },
      "outputs": [],
      "source": [
        "# Define the prompt template\n",
        "PT_scenario = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Dit is het profiel van een fictieve client in het verpleeghuis:\n",
        "---\n",
        "{client_profile}\n",
        "---\n",
        "\n",
        "Schrijf in een tijdlijn het beloop van zijn/haar verblijf in het verpleeghuis gedurende {num_months} maanden.\n",
        "Verwerk de volgende complicatie(s) hierin: {complications}.\n",
        "Hou wijzigingen subtiel. Vermijd al te grote dramatiek.\n",
        "Vermijd het noemen van de naam.\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\",\n",
        "    input_variables=[\"client_profile\", \"num_months\", \"complications\"],\n",
        "    partial_variables={\"format_instructions\": pyd_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "P_scenario = PT_scenario.format(client_profile=\"client profiel\",\n",
        "                                      num_months = 6,\n",
        "                                      complications = \"complicatie(s)\")\n",
        "print(P_scenario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdHaBX_taktA"
      },
      "outputs": [],
      "source": [
        "# Create a chain of operations: prompt template -> model -> output parser\n",
        "chain_scenario = PT_scenario | model | pyd_parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZRfpaEXkxQP"
      },
      "source": [
        "### Main workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpJy9FsfkxQP"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    df_scenarios = main(df=df, chain=chain_scenario, file_path=FN_SCENARIOS)\n",
        "    df_scenarios.head(24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIDdrfE-kxQP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
