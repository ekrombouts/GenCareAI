{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/notebooks/100_note_generation/120_GenerateClientScenarios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKGyZin9teK"
      },
      "source": [
        "# GenCare AI: Generating client scenarios\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:**   13-06-2024  \n",
        "**Updated:** 2024-09-30  \n",
        "**Version:** 2.0\n",
        "\n",
        "### Description\n",
        "This scripts generates client scenarios based on profiles generated [here](https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/notebooks/100_note_generation/110_GenerateClientProfiles.ipynb).\n",
        "\n",
        "Generating scenarios based on 24 client profiles and 8 periods, the cost is approximately $0.03 per run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCvrV851kxQM"
      },
      "outputs": [],
      "source": [
        "!pip install GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "        !pip install -q langchain langchain_core langchain_openai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qke9UwhUFE5z"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6U8-agi-oC9w"
      },
      "outputs": [],
      "source": [
        "# Constants and Configurations\n",
        "ward_name = 'Hermes'\n",
        "fn_profiles = setup.get_file_path(f'data/gcai_client_profiles_{ward_name}.csv')\n",
        "fn_scenarios = setup.get_file_path(f'data/gcai_client_scenarios_{ward_name}.csv')\n",
        "\n",
        "model = 'gpt-3.5-turbo-0125'\n",
        "temp = 1.1\n",
        "\n",
        "duration = 8 # Number of periods\n",
        "duration_sd = 3 # Standard deviation of the number of periods\n",
        "num_complications_min = 1\n",
        "num_complications_max = 3\n",
        "\n",
        "complications_library = [\"gewichtsverlies\", \"algehele achteruitgang\", \"decubitus\", \"urineweginfectie\", \"pneumonie\", \"delier\", \"verergering van onderliggende lichamelijke klachten\", \"verbetering van de klachten\", \"overlijden\", \"valpartij\"]\n",
        "\n",
        "verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ooVq9oALSwXa"
      },
      "outputs": [],
      "source": [
        "# Load the client profiles\n",
        "df = pd.read_csv(fn_profiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-ugZRr6Oarb5"
      },
      "outputs": [],
      "source": [
        "# Pydantic models\n",
        "class ClientScenario(BaseModel):\n",
        "    period: str = Field(description=\"Volgnummer van de periode\")\n",
        "    events_description: str = Field(description=\"Beschrijving van de gebeurtenissen en zorg\")\n",
        "\n",
        "class ClientScenarios(BaseModel):\n",
        "    scenario: List[ClientScenario]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model and parser\n",
        "model = ChatOpenAI(api_key=setup.get_openai_key(), temperature=temp, model=model)\n",
        "pyd_parser = PydanticOutputParser(pydantic_object=ClientScenarios)\n",
        "format_instructions = pyd_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOxQDCbfF1FH"
      },
      "outputs": [],
      "source": [
        "# Define the prompt template\n",
        "template=\"\"\"\n",
        "Dit is het profiel van een fictieve client in het verpleeghuis:\n",
        "---\n",
        "{client_profile}\n",
        "---\n",
        "\n",
        "Schrijf in een tijdlijn het beloop van zijn/haar verblijf in het verpleeghuis gedurende {num_periods} periodes.\n",
        "Verwerk de volgende complicatie(s) hierin: {complications}.\n",
        "Hou wijzigingen subtiel. Vermijd al te grote dramatiek.\n",
        "Vermijd het noemen van de naam.\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"client_profile\", \"num_periods\", \"complications\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "if verbose: \n",
        "    print(prompt_template.format(client_profile=\"client profiel\",\n",
        "                                 num_periods = 6, \n",
        "                                 complications = \"complicatie(s)\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NdHaBX_taktA"
      },
      "outputs": [],
      "source": [
        "# Create a chain of operations: prompt template -> model -> output parser\n",
        "chain_scenario = prompt_template | model | pyd_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate and save scenarios\n",
        "if not os.path.exists(fn_scenarios):\n",
        "    print(\"Data file not found. Generating new data...\")\n",
        "\n",
        "    def generate_scenarios(df, chain):\n",
        "        def display_profile(row):\n",
        "            return (\n",
        "                f\"Naam: {row['naam']}\\n\"\n",
        "                f\"Type Dementie: {row['type_dementie']}\\n\"\n",
        "                f\"Lichamelijke klachten: {row['somatiek']}\\n\"\n",
        "                f\"ADL: {row['adl']}\\n\"\n",
        "                f\"Mobiliteit: {row['mobiliteit']}\\n\"\n",
        "                f\"Cognitie/gedrag: {row['gedrag']}\"\n",
        "            )\n",
        "\n",
        "        def determine_duration(mean=6, std_dev=2):\n",
        "            return int(np.round(np.random.normal(mean, std_dev)))\n",
        "\n",
        "        def determine_num_complications(min=1, max=3):\n",
        "            return random.randint(min, max)\n",
        "\n",
        "        scenario_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            client_profile = display_profile(row)\n",
        "            print(f\"Generating scenario for client: {row['naam']}\")\n",
        "            num_periods = determine_duration(mean=duration, std_dev=duration_sd)\n",
        "            num_complications = determine_num_complications(min=num_complications_min, max=num_complications_max)\n",
        "            chosen_complications = random.sample(complications_library, num_complications)\n",
        "            complications = \", \".join(chosen_complications)\n",
        "\n",
        "            try:\n",
        "                result = chain.invoke({\"client_profile\": client_profile, \"num_periods\": str(num_periods), \"complications\": complications})\n",
        "            except Exception as e:\n",
        "                print(f\"Error encountered: {e}. Retrying...\")\n",
        "                result = chain.invoke({\"client_profile\": client_profile, \"num_periods\": str(num_periods), \"complications\": complications})\n",
        "                print(\"Retry successful\")\n",
        "            \n",
        "            for scenario in result.scenario:\n",
        "                scenario_list.append((row['client_id'], scenario.period, scenario.events_description, complications, num_periods))\n",
        "        return scenario_list\n",
        "\n",
        "    with get_openai_callback() as cb:\n",
        "        scenario_data = generate_scenarios(df, chain_scenario)\n",
        "        print(cb)\n",
        "\n",
        "    df_scenarios = pd.DataFrame(scenario_data, columns=['client_id', 'period', 'events_description', 'complications', 'num_periods'])\n",
        "    df_scenarios.to_csv(fn_scenarios, index=False)\n",
        "    print(f\"Data saved successfully to {fn_scenarios}.\")\n",
        "else:\n",
        "    print(\"Data file found. Loading data...\")\n",
        "    df_scenarios = pd.read_csv(fn_scenarios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if verbose:    \n",
        "    sample_client = 4\n",
        "    def display_profile(row):\n",
        "            return (\n",
        "                f\"Naam: {row['naam']}\\n\"\n",
        "                f\"Type Dementie: {row['type_dementie']}\\n\"\n",
        "                f\"Lichamelijke klachten: {row['somatiek']}\\n\"\n",
        "                f\"ADL: {row['adl']}\\n\"\n",
        "                f\"Mobiliteit: {row['mobiliteit']}\\n\"\n",
        "                f\"Cognitie/gedrag: {row['gedrag']}\"\n",
        "            )\n",
        "    \n",
        "    print(display_profile(df[df['client_id'] == sample_client].iloc[0]))\n",
        "\n",
        "    print(100*'*')\n",
        "    print(df_scenarios[df_scenarios['client_id'] == sample_client][['period', 'events_description']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
