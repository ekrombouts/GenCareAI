{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/olympia/notebooks/100_note_generation/120_GenerateClientScenarios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKGyZin9teK"
      },
      "source": [
        "# GenCare AI: Generating client scenarios\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:**   13-06-2024  \n",
        "**Updated:** 2024-10-07  \n",
        "**Version:** 2.0\n",
        "\n",
        "### Description\n",
        "In previous notebooks, we created a dataset with synthetic progress notes and client profiles for nursing home residents. In this notebook, we will generate client scenarios that describe the course of events during their stay in a psychogeriatric ward. These scenarios aim to provide a timeline of care over several weeks, including complications that may arise during the client’s time in the nursing home.\n",
        "\n",
        "Our goal is to simulate the subtle changes that occur over time in a resident’s health and care needs. Each scenario is generated based on a client profile and includes complications such as weight loss, infections, or other health-related issues. The number of weeks and complications vary to reflect the unpredictability of real-life care trajectories.\n",
        "\n",
        "In this notebook, we use the gpt-4o-mini model to generate these scenarios. The temperature is set to 1.1 to promote variation in the generated content. The ward name is defined to allow for multiple experiments, and the number of weeks is drawn from a normal distribution to ensure variability in the duration of each client’s scenario.\n",
        "\n",
        "This scripts generates client scenarios based on profiles generated [here](todo).\n",
        "\n",
        "Generating scenarios based on 24 client profiles and 20 weeks, the cost is approximately $?? per run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCvrV851kxQM"
      },
      "outputs": [],
      "source": [
        "# Setup dependencies based on environment (e.g., Colab)\n",
        "!pip install GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "        !pip install -q langchain langchain_core langchain_openai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qke9UwhUFE5z"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from GenCareAI import ClientProfileFormatter\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6U8-agi-oC9w"
      },
      "outputs": [],
      "source": [
        "# Initialize constants for scenario generation\n",
        "ward_name = 'Hermes' \n",
        "fn_profiles = setup.get_file_path(f'data/gcai_client_profiles_{ward_name}.csv')\n",
        "fn_scenarios = setup.get_file_path(f'data/gcai_client_scenarios_{ward_name}.csv')\n",
        "\n",
        "model_name = 'gpt-4o-mini-2024-07-18'\n",
        "temp = 1.1\n",
        "\n",
        "duration = 20 # Number of weeks to simulate\n",
        "duration_sd = 6 # Standard deviation of the number of weeks\n",
        "num_complications_min = 1\n",
        "num_complications_max = 3\n",
        "\n",
        "# List of complications to be randomly assigned to clients\n",
        "complications_library = [\n",
        "    \"gewichtsverlies\", \n",
        "    \"algehele achteruitgang\", \n",
        "    \"decubitus\", \n",
        "    \"urineweginfectie\", \n",
        "    \"pneumonie\", \n",
        "    \"delier\", \n",
        "    \"verergering van onderliggende lichamelijke klachten\", \n",
        "    \"verbetering van de klachten\", \n",
        "    \"overlijden\", \n",
        "    \"valpartij\"\n",
        "]\n",
        "\n",
        "verbose = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ooVq9oALSwXa"
      },
      "outputs": [],
      "source": [
        "# Load the client profiles\n",
        "df = pd.read_csv(fn_profiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Pydantic models for handling scenario outputs\n",
        "class ClientScenario(BaseModel):\n",
        "    week: str = Field(description=\"Weeknummer\")\n",
        "    events_description: str = Field(description=\"Beschrijving van de gebeurtenissen en zorg\")\n",
        "\n",
        "class ClientScenarios(BaseModel):\n",
        "    scenario: List[ClientScenario]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XJUm3Dtwz3Rv"
      },
      "outputs": [],
      "source": [
        "# Initialize model and parser\n",
        "model = ChatOpenAI(api_key=setup.get_openai_key(), temperature=temp, model=model_name)\n",
        "pyd_parser = PydanticOutputParser(pydantic_object=ClientScenarios)\n",
        "format_instructions = pyd_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOxQDCbfF1FH"
      },
      "outputs": [],
      "source": [
        "# Define the prompt template\n",
        "template=\"\"\"\n",
        "Dit is het profiel van een fictieve client in het verpleeghuis:\n",
        "---\n",
        "{client_profile}\n",
        "---\n",
        "\n",
        "Schrijf in een tijdlijn het beloop van zijn/haar verblijf in het verpleeghuis gedurende {num_weeks} weken.\n",
        "Verwerk de volgende complicatie(s) hierin: {complications}.\n",
        "\n",
        "Instructies:\n",
        "- Zorg dat een individuele scenarioregel wordt begrepen door een taalmodel. Het scenario zal later worden gebruikt voor het genereren van fictieve rapportages.\n",
        "- Hou wijzigingen subtiel. Vermijd al te grote dramatiek. \n",
        "\n",
        "{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"client_profile\", \"num_weeks\", \"complications\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "if verbose:\n",
        "    print(prompt_template.format(client_profile=\"client profiel\",\n",
        "                                 num_weeks = 21,\n",
        "                                 complications = \"complicatie(s)\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NdHaBX_taktA"
      },
      "outputs": [],
      "source": [
        "# Create a chain of operations: prompt template -> model -> output parser\n",
        "chain_scenario = prompt_template | model | pyd_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_QL3H8iz3Rv"
      },
      "outputs": [],
      "source": [
        "# Generate and save scenarios\n",
        "if not os.path.exists(fn_scenarios):\n",
        "    print(\"Data file not found. Generating new data...\")\n",
        "\n",
        "    def generate_scenarios(df, chain):\n",
        "        from GenCareAI import ClientProfileFormatter\n",
        "        cpf = ClientProfileFormatter()\n",
        "\n",
        "        # Function to determine the scenario duration (weeks) based on normal distribution\n",
        "        def determine_duration(mean=6, std_dev=2):\n",
        "            return int(np.round(np.random.normal(mean, std_dev)))\n",
        "\n",
        "        # Function to determine the number of complications to be included\n",
        "        def determine_num_complications(min=1, max=3):\n",
        "            return random.randint(min, max)\n",
        "\n",
        "        scenario_list = []\n",
        "        for _, row in tqdm(df.iterrows(), total = df.shape[0], desc=\"Generating Scenario's\"):\n",
        "            # Format the client profile\n",
        "            client_profile = cpf.format_client_profile(\n",
        "                profile_row=row,\n",
        "                display_name=False\n",
        "            )\n",
        "            # print(f\"Generating scenario for client: {row['naam']}\")\n",
        "            # Determine the number of weeks and complications for the scenario\n",
        "            num_weeks = determine_duration(mean=duration, std_dev=duration_sd)\n",
        "            num_complications = determine_num_complications(min=num_complications_min, max=num_complications_max)\n",
        "            chosen_complications = random.sample(complications_library, num_complications)\n",
        "            complications = \", \".join(chosen_complications)\n",
        "\n",
        "            # Invoke the model. \n",
        "            # Errors are frequently due to incorrectly formatted responses, causing parsing errors. A simple retry often does the trick.\n",
        "            try:\n",
        "                result = chain.invoke({\"client_profile\": client_profile, \"num_weeks\": str(num_weeks), \"complications\": complications})\n",
        "            except Exception as e:\n",
        "                print(f\"Error encountered: {e}. Retrying...\")\n",
        "                result = chain.invoke({\"client_profile\": client_profile, \"num_weeks\": str(num_weeks), \"complications\": complications})\n",
        "                print(\"Retry successful\")\n",
        "\n",
        "            # Store the results in the scenario_list\n",
        "            for scenario in result.scenario:\n",
        "                scenario_list.append((row['client_id'], scenario.week, scenario.events_description, complications, num_weeks))\n",
        "        return scenario_list\n",
        "\n",
        "    with get_openai_callback() as cb:\n",
        "        scenario_data = generate_scenarios(df, chain_scenario)\n",
        "        print(cb)\n",
        "\n",
        "    df_scenarios = pd.DataFrame(scenario_data, columns=['client_id', 'week', 'events_description', 'complications', 'num_weeks'])\n",
        "    df_scenarios.to_csv(fn_scenarios, index=False)\n",
        "    print(f\"Data saved successfully to {fn_scenarios}.\")\n",
        "else:\n",
        "    print(\"Data file found. Loading data...\")\n",
        "    df_scenarios = pd.read_csv(fn_scenarios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXJDjLmTz3Rw"
      },
      "outputs": [],
      "source": [
        "if verbose:\n",
        "    sample_client = 3\n",
        "    cpf = ClientProfileFormatter()\n",
        "\n",
        "    print(cpf.format_client_profile(\n",
        "        profile_row=df[df['client_id'] == sample_client].iloc[0])\n",
        "    )\n",
        "\n",
        "    print(100*'-')\n",
        "\n",
        "    ct_scens = df_scenarios[df_scenarios['client_id'] == sample_client][['week', 'events_description']]\n",
        "    for i, s in enumerate(ct_scens.itertuples(), 1):\n",
        "        print(f\"{i}. {s.events_description}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gcai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
