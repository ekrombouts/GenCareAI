{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/notebooks/100_note_generation/140_GenerateClientRecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36HQ18HpIXWc"
      },
      "source": [
        "# GenCare AI: Generating client records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikaQICHjIXWc"
      },
      "source": [
        "## Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW7h9ktIIXWc"
      },
      "source": [
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:** 2024-06-15  \n",
        "**Updated:** 2024-10-10  \n",
        "**Version:** 2.0\n",
        "\n",
        "### Description\n",
        "This notebook generates synthetic care records for fictional clients in nursing homes. It uses client profiles and weekly scenarios created in earlier notebooks. Example notes are pulled from a Chroma vector database and filtered based on gender to avoid mismatches in pronouns. A GPT-based model then generates 21 care notes per week for each client. The goal is to create diverse data that can be used for analysis or machine learning tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gy6D4IpIXWc"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ1bfnlEKFlJ"
      },
      "outputs": [],
      "source": [
        "!pip install -U GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup, ClientProfileFormatter\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "        !pip install -q langchain langchain-openai langchain-community langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SBUj6OfchJdh"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OPlGqU5ehTX9"
      },
      "outputs": [],
      "source": [
        "# Paths to various data files and constants for the model and temperature settings.\n",
        "ward_name = 'Dahlia' # Make sure to use the same ward-name for which clientprofiles and -scenarios have been generated\n",
        "path_profiles = setup.get_file_path(f'data/gcai_client_profiles_{ward_name}.csv')\n",
        "path_scenarios = setup.get_file_path(f'data/gcai_client_scenarios_{ward_name}.csv')\n",
        "path_notes = setup.get_file_path(f'data/gcai_client_notes_{ward_name}.csv')\n",
        "\n",
        "# Path to the Chroma vector database\n",
        "path_db_gcai = setup.get_file_path('data/chroma_db_gcai')\n",
        "collection_name = 'Gardenia'\n",
        "num_examples = 3\n",
        "\n",
        "model_notes = 'gpt-3.5-turbo-0125'\n",
        "model_embeddings = 'text-embedding-ada-002'\n",
        "temp_notes = 1.1\n",
        "\n",
        "verbose = False # Toggle for printing debug information\n",
        "sample_client_id = 3\n",
        "sample_weekno = 2\n",
        "sep_line = '-' * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNrTxrG6IXWe"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "izOidhlgsViG"
      },
      "outputs": [],
      "source": [
        "# Load scenarios and profiles from CSV files\n",
        "df_scenarios = pd.read_csv(path_scenarios)\n",
        "df_profiles = pd.read_csv(path_profiles)\n",
        "\n",
        "if verbose:\n",
        "    print(df_profiles.info())\n",
        "    print(df_scenarios.info())\n",
        "\n",
        "if verbose:\n",
        "    # Select the profile row for the sample client\n",
        "    sample_profile_row = df_profiles.loc[df_profiles['client_id'] == sample_client_id].iloc[0]\n",
        "\n",
        "    # Select the scenario row for the sample client and scenario\n",
        "    sample_scenario_row = df_scenarios.loc[\n",
        "        (df_scenarios['client_id'] == sample_client_id) &\n",
        "        (df_scenarios['week'] == sample_weekno)\n",
        "    ].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dbg9LS_2IXWe"
      },
      "outputs": [],
      "source": [
        "# Format and print the profile and scenario for the sample client\n",
        "if verbose:\n",
        "    cpf = ClientProfileFormatter()\n",
        "    sample_profile = cpf.format_client_profile(\n",
        "        profile_row=sample_profile_row\n",
        "    )\n",
        "    print(sample_profile)\n",
        "    print(sep_line)\n",
        "    sample_scenario = sample_scenario_row['events_description']\n",
        "    print(sample_scenario)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1rI3ZiNOT-3"
      },
      "source": [
        "## Setting up the example library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kxr8AlVwIXWe"
      },
      "outputs": [],
      "source": [
        "# Retrieving notes for the example library\n",
        "# Initialize Chroma vector database\n",
        "vectordb = Chroma(\n",
        "    persist_directory=path_db_gcai,\n",
        "    embedding_function=OpenAIEmbeddings(api_key=setup.get_openai_key(), model=model_embeddings),\n",
        "    collection_name = collection_name\n",
        "    )\n",
        "\n",
        "# Define a retriever\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 40})\n",
        "\n",
        "# Function to retrieve example notes\n",
        "def retrieve_examples (profile, retriever):\n",
        "    text = profile\n",
        "    example_library = []\n",
        "    documents = retriever.invoke(text)\n",
        "    for document in documents:\n",
        "        example_library.append(document.page_content.strip('\"'))\n",
        "\n",
        "    return example_library\n",
        "\n",
        "# Retrieve example library based on the formatted profile\n",
        "if verbose:\n",
        "    example_library = retrieve_examples(\n",
        "        profile=cpf.format_client_profile(\n",
        "            profile_row=sample_profile_row,\n",
        "            display_diagnosis=False\n",
        "        ),\n",
        "        retriever=retriever)\n",
        "    for i in example_library[0:5]:\n",
        "        print(f\"- {i}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXQ23jTlIXWe"
      },
      "source": [
        "The example notes often contain gender-specific pronouns or titles. When these are included in the prompt the model tends to generate responses with incorrect pronouns for our client. Therefore, we need to filter the example library to exclude notes that use ‘mr’ or ‘mrs’."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "veiOeNbiG7UF"
      },
      "outputs": [],
      "source": [
        "def filter_notes_by_gender(notes, gender):\n",
        "    \"\"\"\n",
        "    Filters example notes based on the specified gender to ensure relevance.\n",
        "\n",
        "    Args:\n",
        "    notes (list): List of example notes to filter.\n",
        "    gender (str): Gender to filter for ('male', 'female', or 'unknown').\n",
        "\n",
        "    Returns:\n",
        "    list: Filtered list of example notes.\n",
        "    \"\"\"\n",
        "    if gender == 'male':\n",
        "        gender_words = ['mw', 'mevr', 'mvr', 'mevrouw']\n",
        "    elif gender == 'female':\n",
        "        gender_words = ['dhr', 'meneer']\n",
        "    else:\n",
        "        return notes  # No filtering for unknown gender\n",
        "\n",
        "    def contains_gender_words(note):\n",
        "        return any(gender_word in note.lower() for gender_word in gender_words)\n",
        "\n",
        "    return [note for note in notes if not contains_gender_words(note)]\n",
        "\n",
        "if verbose:\n",
        "    ex_lib_gender_filtered = filter_notes_by_gender(\n",
        "        notes=example_library,\n",
        "        gender=cpf.determine_client_gender(\n",
        "            profile_row=sample_profile_row))\n",
        "\n",
        "    [print('- '+item) for item in random.sample(ex_lib_gender_filtered, 5)]\n",
        "\n",
        "    print(f\"\\nOorspronkelijk aantal voorbeelden: {len(example_library)}\")\n",
        "    print(f\"Gefilterd aantal voorbeelden: {len(ex_lib_gender_filtered)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "442QXJv-wVAG"
      },
      "outputs": [],
      "source": [
        "def sample_and_format_example_library(example_library, num_items=3):\n",
        "    \"\"\"\n",
        "    Selects a random set of examples from the example library and returns them as a bulleted string.\n",
        "\n",
        "    Args:\n",
        "    example_library (list): List of example notes.\n",
        "    num_items (int): Number of random items to select.\n",
        "\n",
        "    Returns:\n",
        "    str: A formatted string of the randomly selected notes.\n",
        "    \"\"\"\n",
        "    random_items = random.sample(example_library, num_items)\n",
        "    return '\\n'.join(['- ' + item for item in random_items])\n",
        "\n",
        "if verbose:\n",
        "    ex_lib_sample = sample_and_format_example_library(ex_lib_gender_filtered, 5)\n",
        "    print(ex_lib_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRpEWBBDIXWe"
      },
      "source": [
        "## Generating client notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zr7gHvL7eA0a"
      },
      "outputs": [],
      "source": [
        "#Structure for a single care note\n",
        "class CareNote(BaseModel):\n",
        "    dag: int = Field(description=\"volgnummer dag\")\n",
        "    tijd: str = Field(description=\"tijd van de rapportage (hh:mm)\")\n",
        "    rapportage: str = Field(description=\"Inhoud van de rapportage. Een rapportage beschrijft over het algemeen één zorgaspect, soms meer\")\n",
        "\n",
        "# Structure for multiple notes\n",
        "class CareNotes(BaseModel):\n",
        "    notes: List[CareNote] = Field(description=\"Rapportages voor een week, drie per dag. Totaal 21 rapportages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RhQN6Cz1IXWf"
      },
      "outputs": [],
      "source": [
        "# Define the OpenAI model to generate notes\n",
        "notes_model = ChatOpenAI(\n",
        "    api_key=setup.get_openai_key(),\n",
        "    temperature=temp_notes,\n",
        "    model=model_notes,\n",
        "    max_tokens=2048)\n",
        "\n",
        "# Parser for model output\n",
        "notes_parser = PydanticOutputParser(pydantic_object=CareNotes)\n",
        "notes_format_instructions = notes_parser.get_format_instructions()\n",
        "if verbose:\n",
        "    print(notes_format_instructions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWIt5YIZnVSw"
      },
      "source": [
        "### Note generation prompts & chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fDOze-TcewR1"
      },
      "outputs": [],
      "source": [
        "notes_template = \"\"\"**SCENARIO**\n",
        "{scenario}\n",
        "**EINDE SCENARIO**\n",
        "\n",
        "Schrijf rapportages op basis van dit scenario van een fictieve client die verblijft op een psychogeriatrische afdeling van het verpleeghuis. De rapportages staan op zich, maar zorg voor een subtiele en geleidelijke opbouw zodat ze samen het verhaal van de client vertellen.\n",
        "\n",
        "Schrijf rapportages voor een week (7 dagen). Per dag worden drie rapportages geschreven, dus er zijn 21 rapportages totaal.\n",
        "\n",
        "Profiel van de client:\n",
        "{profile}\n",
        "\n",
        "Instructies:\n",
        "- **Volg het scenario nauwkeurig**\n",
        "- Vermijd het noemen van de naam van de client.\n",
        "- Je spreekt de taal van een niveau 3 zorgmedewerker (Verzorgende IG).  Varieer in zinsopbouw en stijl, soms zijn de rapportages langer en meer gedetailleerd.\n",
        "- Zorg dat de beschreven zorg realistisch is. Een fysiotherapeut komt niet elke dag langs, bijvoorbeeld\n",
        "\n",
        "Voorbeeld rapportages (herhaal deze niet, maar gebruik ze als leidraad):\n",
        "{examples}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "# Define the prompt template with variables and partial instructions\n",
        "notes_prompt_template = PromptTemplate(\n",
        "    template=notes_template,\n",
        "    input_variables=[\"scenario\", \"profile\", \"examples\"],\n",
        "    partial_variables={\"format_instructions\": notes_format_instructions},\n",
        ")\n",
        "\n",
        "if verbose:\n",
        "    notes_prompt = notes_prompt_template.format(\n",
        "        scenario = sample_scenario,\n",
        "        profile = sample_profile,\n",
        "        examples = sample_and_format_example_library(ex_lib_gender_filtered,3),\n",
        "        )\n",
        "    print(notes_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-PkN3p7AIXWf"
      },
      "outputs": [],
      "source": [
        "# Define chain for generating notes\n",
        "notes_chain = notes_prompt_template | notes_model | notes_parser\n",
        "\n",
        "# Function to generate care notes for a client\n",
        "def generate_notes(profile, scenario, examples):\n",
        "    try:\n",
        "        notes = notes_chain.invoke({\n",
        "            \"scenario\": scenario,\n",
        "            \"profile\": profile,\n",
        "            \"examples\": examples,\n",
        "        })\n",
        "    except Exception as e:\n",
        "        # Try once more in case of failure\n",
        "        print(f\"Error in generating notes, retrying...\")\n",
        "        notes = notes_chain.invoke({\n",
        "            \"scenario\": scenario,\n",
        "            \"profile\": profile,\n",
        "            \"examples\": examples,\n",
        "        })\n",
        "        print(\"Retry successful\")\n",
        "\n",
        "    return notes.notes # Return the list of generated notes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Bp3QOC9sIXWf"
      },
      "outputs": [],
      "source": [
        "def process_client(df_profile_row, df_scenarios):\n",
        "    cpf = ClientProfileFormatter()\n",
        "    client_id = df_profile_row['client_id']\n",
        "\n",
        "    # Format the client profile for the prompt\n",
        "    profile = cpf.format_client_profile(df_profile_row, display_name=False)\n",
        "    client_gender = cpf.determine_client_gender(df_profile_row)\n",
        "\n",
        "    # Initialize a list to store generated notes with metadata\n",
        "    ct_notes = []\n",
        "\n",
        "    # Set up the retriever\n",
        "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 20})\n",
        "\n",
        "    # Loop over the scenarios\n",
        "    with get_openai_callback() as cb:\n",
        "        for idx, scenario_row in tqdm(df_scenarios.iterrows(), total=df_scenarios.shape[0], desc=\"Processing Scenarios\"):\n",
        "            # Retrieve the current scenario description\n",
        "            scenario = scenario_row['events_description']\n",
        "            scenario_id = scenario_row['week']\n",
        "\n",
        "            # Generate example notes based on the client profile and scenario\n",
        "            example_library = retrieve_examples(\n",
        "                profile=profile,\n",
        "                retriever=retriever\n",
        "            )\n",
        "            ex_lib_gender_filtered = filter_notes_by_gender(\n",
        "                notes=example_library,\n",
        "                gender=client_gender\n",
        "            )\n",
        "            ex_lib_sample = sample_and_format_example_library(\n",
        "                example_library=ex_lib_gender_filtered,\n",
        "                num_items=num_examples\n",
        "            )\n",
        "\n",
        "            # Generate care notes for the current scenario\n",
        "            result_notes = generate_notes(\n",
        "                scenario=scenario,\n",
        "                profile=profile,\n",
        "                examples=ex_lib_sample\n",
        "            )\n",
        "\n",
        "            # Add generated notes to the notes list along with metadata\n",
        "            for note in result_notes:\n",
        "                ct_notes.append({\n",
        "                    \"client_id\": client_id,\n",
        "                    \"weekno\": scenario_id,\n",
        "                    \"dag\": note.dag,\n",
        "                    \"tijd\": note.tijd,\n",
        "                    \"rapportage\": note.rapportage,\n",
        "                })\n",
        "\n",
        "        print(f\"Cost for client {client_id}: {cb.total_cost}\")\n",
        "\n",
        "    return ct_notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JYNCmDLpIXWf"
      },
      "outputs": [],
      "source": [
        "def process_clients(df_profiles, df_scenarios, output_path):\n",
        "    # Check if output_path exists\n",
        "    if os.path.exists(output_path):\n",
        "        # Read in existing data\n",
        "        existing_notes_df = pd.read_csv(output_path)\n",
        "    else:\n",
        "        existing_notes_df = pd.DataFrame()\n",
        "\n",
        "    # Loop through each client profile\n",
        "    for _, df_profile_row in tqdm(df_profiles.iterrows(), total=df_profiles.shape[0], desc=\"Processing Clients\"):\n",
        "        client_id = df_profile_row['client_id']\n",
        "\n",
        "        # Check which weeks are already processed for this client\n",
        "        if not existing_notes_df.empty:\n",
        "            processed_weeks = set(existing_notes_df[existing_notes_df['client_id'] == client_id]['weekno'].unique())\n",
        "        else:\n",
        "            processed_weeks = set()\n",
        "\n",
        "        # Get the scenarios for this client that have not yet been processed\n",
        "        client_scenarios = df_scenarios[df_scenarios['client_id'] == client_id]\n",
        "        unprocessed_scenarios = client_scenarios[~client_scenarios['week'].isin(processed_weeks)]\n",
        "\n",
        "        # If all scenarios are processed, skip to next client\n",
        "        if unprocessed_scenarios.empty:\n",
        "            print(f\"Client {client_id} is already fully processed. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Generate notes for the current client\n",
        "        client_notes = process_client(\n",
        "            df_profile_row=df_profile_row,\n",
        "            df_scenarios=unprocessed_scenarios,  # Pass unprocessed scenarios only\n",
        "        )\n",
        "\n",
        "        # Convert client_notes to DataFrame\n",
        "        client_notes_df = pd.DataFrame(client_notes)\n",
        "\n",
        "        # Append new notes to existing_notes_df\n",
        "        if not existing_notes_df.empty:\n",
        "            existing_notes_df = pd.concat([existing_notes_df, client_notes_df], ignore_index=True)\n",
        "        else:\n",
        "            existing_notes_df = client_notes_df\n",
        "\n",
        "        # Save the combined notes to a CSV file after each client\n",
        "        existing_notes_df.to_csv(output_path, index=False)\n",
        "        print(f\"Data saved to {output_path} after processing client {client_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGk5hpHUIXWf"
      },
      "outputs": [],
      "source": [
        "process_clients(\n",
        "    df_profiles=df_profiles,\n",
        "    df_scenarios=df_scenarios,\n",
        "    output_path=path_notes,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs_gH5_3IXWf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gcai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
