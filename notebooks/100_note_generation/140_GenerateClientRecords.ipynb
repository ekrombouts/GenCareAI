{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/notebooks/100_note_generation/140_GenerateClientRecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["# GenCare AI: Generating client records\n","\n","**Author:** Eva Rombouts  \n","**Date:** 2024-06-15  \n","**Updated:** 2024-09-01  \n","**Version:** 1.2\n","\n","### Description\n","This script generates synthetic care notes and summaries for clients in a psychogeriatric ward using the OpenAI GPT-3.5-turbo model.  \n","The care notes are based on client profiles and scenarios generated in earlier scripts in this repo. The goal is to add as much story and variation to the notes as possible, without letting the model produce outputs that are overly creative.  \n","To achieve this, I use structured prompts (to help the model understand the expected content and its creative liberties), example libraries and memory integration.  \n","The output parser uses Pydantic models to structure and validate the care notes, ensuring proper format and content.  \n","Chroma is used to retrieve example care notes that are representative of the client profile and scenario. \n","\n","The script processes client profiles and scenarios, generates care notes, and updates summaries accordingly, creating comprehensive client records.  \n","The goal is to create a diverse and realistic dataset for NLP experiments in nursing homes.\n","\n","**Please note** that generating data with OpenAI is not free. Generating records for 24 clients with a mean of 8 months, 5 iterations per month takes about 3 hours en costs appr $2,- with gpt-3.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQ1bfnlEKFlJ"},"outputs":[],"source":["!pip install GenCareAI\n","from GenCareAI.GenCareAIUtils import GenCareAISetup\n","\n","setup = GenCareAISetup()\n","\n","if setup.environment == 'Colab':\n","        !pip install -q langchain langchain-openai langchain-community langchain-chroma"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBUj6OfchJdh"},"outputs":[],"source":["# Imports\n","import random\n","import pandas as pd\n","from pprint import pprint\n","from typing import List\n","\n","from langchain.output_parsers import PydanticOutputParser, CommaSeparatedListOutputParser\n","# from langchain.prompts import ChatPromptTemplate \n","from langchain_chroma import Chroma\n","from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain_community.callbacks import get_openai_callback"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPlGqU5ehTX9"},"outputs":[],"source":["# Paths to various data files and constants for the model and temperature settings.\n","PATH_DB_GCAI = setup.get_file_path('data/chroma_db_gcai_notes')\n","WARD_NAME = 'Athena' # Make sure to use the same ward-name for which clientprofiles and -scenarios have been generated\n","PATH_PROFILES = setup.get_file_path(f'data/gcai_client_profiles_{WARD_NAME}.csv')\n","PATH_SCENARIOS = setup.get_file_path(f'data/gcai_client_scenarios_{WARD_NAME}.csv')\n","PATH_NOTES = setup.get_file_path(f'data/gcai_client_notes_{WARD_NAME}.csv')\n","PATH_SUMMARIES = setup.get_file_path(f'data/gcai_client_summaries_{WARD_NAME}.csv')\n","\n","COLLECTION_NAME = 'anonymous_notes'\n","MODEL = 'gpt-3.5-turbo-0125'\n","MODEL_EMBEDDINGS = 'text-embedding-ada-002'\n","TEMP = 1.1\n","\n","VERBOSE = True # Set to True for debugging / printing\n","TEST_CLIENT_ROW_NUMBER = 2\n","SEP_LINE = 100*'-'"]},{"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"markdown","metadata":{},"source":["In the notebooks [110_GenerateClientProfiles.ipynb]() and [120_GenerateClientScenarios.ipynb](), datasets are generated with client profiles and scenarios, respectively.\n","\n","- ***df_profiles***: Contains one row per client. The row describes the type of dementia the client is diagnosed with, the ADL care needs, medical symptoms and diseases, mobility, and behavior.\n","  \n","- ***df_scenarios***: Each client has zero or more scenario lines. These are referred to as month numbers, but they do not necessarily correspond to actual months."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izOidhlgsViG"},"outputs":[],"source":["# Load scenarios and profiles from CSV files\n","df_scenarios = pd.read_csv(PATH_SCENARIOS)\n","df_profiles = pd.read_csv(PATH_PROFILES)\n","\n","if VERBOSE:\n","    print(df_profiles.info())\n","    print(df_scenarios.info())\n","    test_client = df_profiles.iloc[TEST_CLIENT_ROW_NUMBER] # We will be using this test client throughout the script"]},{"cell_type":"markdown","metadata":{},"source":["### Functions to display the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GbaiLoeX5egO"},"outputs":[],"source":["# Function to format the client’s profile information as a single string\n","def profile_as_string(profile_row, display_name=True):\n","    profile = \"\"\n","    if display_name:\n","        profile += f\"Naam: {profile_row['naam']}\\n\"\n","    profile += (f\"Type Dementie: {profile_row['type_dementie']}\\n\"\n","                f\"Lichamelijke klachten: {profile_row['somatiek']}\\n\"\n","                f\"ADL: {profile_row['adl']}\\n\"\n","                f\"Mobiliteit: {profile_row['mobiliteit']}\\n\"\n","                f\"Cognitie / gedrag: {profile_row['gedrag']}\")\n","    return profile\n","\n","if VERBOSE:\n","    print(profile_as_string(profile_row=test_client, display_name=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ofM_6CwQ1HfE"},"outputs":[],"source":["# Function to display the scenario information for a given client and month\n","def scenario_as_string(profile_row, month_no=1):\n","    client_id = profile_row['client_id']\n","    return df_scenarios.loc[df_scenarios['client_id'] == client_id, 'journey'].iloc[month_no - 1]\n","    \n","if VERBOSE:\n","    print(scenario_as_string(profile_row=test_client))\n","    print(scenario_as_string(profile_row=test_client, month_no=2))"]},{"cell_type":"markdown","metadata":{},"source":["### Define Pydantic models"]},{"cell_type":"markdown","metadata":{},"source":["For parsing, we use pydantic models. These are remarkably well understood by the LLM, and offer several benefits:\n","- It enforces consistent output structure\n","- It automates parsing of the output\n","- The field description further guides the LLM model in generating appropriate responses. \n","- It catches invalid data early, preventing downstream issues.\n","\n","In our main prompt defined below, we ask the LLM to generate multiple care notes. Our structure consists of two classes: one to structure a single note (CareNote) and a second class defined as a list of care notes (CareNotes).\n","\n","CareNote represents a single care note with the fields dag, tijd, and rapportage:\n","- **'dag'**: Even though the sequence number of the day (\"dag\") isn't meaningful, it forces the model to respond with the number of days requested.  \n","- **'tijd'**: The field 'time' (\"tijd\") was chosen over 'daypart' (\"dagdeel\") because the model tended to link 'daypart' to breakfast, lunch, and dinner, which led to many notes describing lunch details.  \n","- **'rapportage'**: This is the main challenge, what it's all about... \n","\n","CareNotes is a container for multiple care notes, consisting of a single field **'notes'**, which is a list of CareNote instances."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zr7gHvL7eA0a"},"outputs":[],"source":["#Structure for a single care note\n","class CareNote(BaseModel):\n","    dag: int = Field(description=\"volgnummer dag\")\n","    tijd: str = Field(description=\"tijd van de rapportage (hh:mm)\")\n","    rapportage: str = Field(description=\"Inhoud van de rapportage. Een rapportage beschrijft over het algemeen één zorgaspect, soms meer\")\n","\n","# Structure for multiple notes\n","class CareNotes(BaseModel):\n","    notes: List[CareNote]"]},{"cell_type":"markdown","metadata":{"id":"WuLEAtDEcd3P"},"source":["### Model initialization"]},{"cell_type":"markdown","metadata":{},"source":["The temperature and model settings can be configured in the constants section. I selected the OpenAI GPT-3.5-turbo model for cost-efficiency. The temperature setting of 1.1 was determined through trial and error."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SY05Xi9jIpQU"},"outputs":[],"source":["# Initialize OpenAI Chat model\n","model = ChatOpenAI(api_key=setup.get_openai_key(), temperature=TEMP, model=MODEL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"704bo7ZvI3Rb"},"outputs":[],"source":["# Initialize CSV and pydantic parsers\n","csv_parser = CommaSeparatedListOutputParser()\n","csv_format_instructions = csv_parser.get_format_instructions()\n","pyd_parser = PydanticOutputParser(pydantic_object=CareNotes)"]},{"cell_type":"markdown","metadata":{"id":"_1rI3ZiNOT-3"},"source":["## Setting up the example library"]},{"cell_type":"markdown","metadata":{},"source":["### Setup Chroma"]},{"cell_type":"markdown","metadata":{},"source":["To improve the contextual relevance and diversity of the generated care notes, we will dynamically inject example notes into the prompts. \n","\n","Chroma is used in this context to select example care notes that are representative of the client profile and scenario. By using a vector database, the system can efficiently find example notes that match the specific characteristics of each client. The Chroma vector database, created [here](), contains a variety of (synthetic) notes for anonymous clients. The retriever queries this database, allowing the processing functions to access and integrate the stored example notes.  \n","By adding these dynamically selected examples to the prompt, this approach aims to make the generated care notes more contextually appropriate and diverse.\n","\n","Our approach is:\n","- Initialize the Chroma Vector Database.\n","- Generate Keywords: Using the LLM, keywords are generated from a client’s profile and scenario. These keywords are used to query the Chroma vector database for relevant example notes.\n","- Retrieve Example Notes: Utilizing a retriever to search the vector database with the generated keywords, supplemented by additional neutral terms to ensure a broad coverage of relevant care notes.\n","- Filter by Gender: Filter the retrieved example notes to exclude those with gender-specific pronouns that do not match the client’s gender, ensuring the relevance of the examples.\n","- Sample Examples: Randomly sample a subset of the filtered example notes to inject into the prompts, enhancing the diversity of the generated care notes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qqLzQ6ybOSf_"},"outputs":[],"source":["# Initialize Chroma vector database\n","vectordb = Chroma(persist_directory=PATH_DB_GCAI,\n","                  embedding_function=OpenAIEmbeddings(api_key=setup.get_openai_key(), model=MODEL_EMBEDDINGS),\n","                  collection_name = COLLECTION_NAME\n","                  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiyfD9lzO-jG"},"outputs":[],"source":["# Set up a retriever for document querying\n","retriever = vectordb.as_retriever(search_kwargs={\"k\": 20})"]},{"cell_type":"markdown","metadata":{"id":"1DrpAyfzCh4q"},"source":["### Keywords prompt & chain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WsHfOsy1Coqt"},"outputs":[],"source":["# Template to generate key words from a client’s profile and scenario for retrieving example notes\n","PT_keywords = PromptTemplate(\n","    template = \"\"\"\n","Geef vijf woorden die de kern weergeven van onderstaand profiel en scenario.\n","Geef geen namen terug.\n","\n","Profiel:\n","{profile}\n","\n","Scenario:\n","{scenario}\n","\n","{format_instructions}\n","\"\"\",\n","    input_variables=[\"profile\", \"scenario\"],\n","    partial_variables={\"format_instructions\": csv_format_instructions},)\n","\n","# Format the prompt for the example library\n","if VERBOSE:\n","    P_keywords = PT_keywords.format(\n","        profile=profile_as_string(test_client, display_name=False), \n","        scenario=scenario_as_string(test_client, month_no=1))\n","    print(P_keywords)"]},{"cell_type":"markdown","metadata":{},"source":["The code below shows us the result of passing this prompt to the model. The result is a langchain_core.messages.ai.AIMessage object. The 'content' parameter holds the AI message (the response) as a string. As requested by the format instructions in the prompt, this is a comma separated 'list' of values.\n","Passing this string to the CommaSeparatedListOutputParser results in an actual python list.\n","\n","The model often returns more than the five requested keywords. Since this has minor consequences, I accept this behavior."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if VERBOSE:\n","    response_keywords = model.invoke(P_keywords)\n","    parsed_response_keywords = csv_parser.parse(response_keywords.content)\n","\n","    print(response_keywords)\n","    print(100 * '-')\n","    print(parsed_response_keywords)\n","    print(100 * '-')"]},{"cell_type":"markdown","metadata":{},"source":["Chaining it all together"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0T1E8Q5GIua5"},"outputs":[],"source":["# Chain the prompt template with the model and the parser\n","chain_keywords = PT_keywords | model | csv_parser\n","\n","if VERBOSE:\n","    test_keywords = chain_keywords.invoke(\n","        {\"profile\": profile_as_string(test_client, display_name=False), \n","         \"scenario\": scenario_as_string(test_client, month_no=1)})\n","    print(test_keywords)"]},{"cell_type":"markdown","metadata":{},"source":["### Retrieving notes for the example library"]},{"cell_type":"markdown","metadata":{},"source":["The next step is to invoke the retriever with the generated keywords to obtain example notes. To add more ‘neutral’ notes, we also add the keywords ‘ADL’, ‘mobility’, and ‘food and drinks’ to the list.\n","\n","Please note: The retriever utilizes an OpenAI embedding model (which is not free), which transforms the keywords into embeddings. These embeddings are then used to find similar notes in the initialized vector database, ensuring the retrieval of contextually relevant examples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hFPwNOvzCodj"},"outputs":[],"source":["# Retrieves example notes from a retriever based on keywords\n","def get_example_notes(keywords, retriever):\n","    example_library = []\n","    example_library_topics = keywords\n","    example_library_topics.extend(['adl', 'mobiliteit', 'eten en drinken'])\n","    for i in example_library_topics:\n","        docs = retriever.invoke(i)\n","        for d in docs:\n","            example_library.append(d.page_content.strip('\"'))\n","    return example_library\n","\n","if VERBOSE:\n","    example_notes = get_example_notes(test_keywords, retriever)\n","    print(random.sample(example_notes,5))\n","    print(len(example_notes))"]},{"cell_type":"markdown","metadata":{},"source":["The example notes often contain gender-specific pronouns or titles. When these are included in the prompt the model tends to generate responses with incorrect pronouns for our client. Therefore, we need to filter the example library to exclude notes that use ‘mr’ or ‘mrs’."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmhxUh5G2_GO"},"outputs":[],"source":["# Determines the gender of a client based on their name\n","def determine_gender(name):\n","    if \"Mevrouw\" in name:\n","        return 'female'\n","    elif \"Meneer\" in name:\n","        return 'male'\n","    else:\n","        return 'unknown'\n","    \n","if VERBOSE:\n","    print(f\"The gender of {test_client['naam']} is: {determine_gender(test_client['naam'])}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"veiOeNbiG7UF"},"outputs":[],"source":["# Filters example notes by the specified gender to ensure relevance\n","def filter_examples_by_gender(texts, gender_to_keep):\n","    if gender_to_keep == 'male':\n","        keywords = ['mw', 'mevr', 'mvr', 'mevrouw']\n","    elif gender_to_keep == 'female':\n","        keywords = ['dhr', 'meneer']\n","    else:\n","        return texts\n","\n","    def contains_keywords(text):\n","        text_lower = text.lower()\n","        return any(keyword in text_lower for keyword in keywords)\n","\n","    return [text for text in texts if not contains_keywords(text)]\n","\n","if VERBOSE:\n","    test_example_library = filter_examples_by_gender(texts=example_notes, gender_to_keep=determine_gender(test_client['naam']))\n","    [print('- '+item) for item in random.sample(test_example_library, 5)]\n","    print(f\"\\nOorspronkelijk aantal voorbeelden: {len(example_notes)}\")\n","    print(f\"Gefilterd aantal voorbeelden: {len(test_example_library)}\")"]},{"cell_type":"markdown","metadata":{},"source":["We'll be sampling a subset of this library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"442QXJv-wVAG"},"outputs":[],"source":["# Selects a random set of examples from the example library and returns as bulleted string\n","def sample_examples_as_string(example_library, num_items=3):\n","    random_items = random.sample(example_library, num_items)\n","    return '\\n'.join(['- ' + item for item in random_items])\n","\n","if VERBOSE:\n","    sampled_examples_as_string = sample_examples_as_string(test_example_library, 5)\n","    print(sampled_examples_as_string)"]},{"cell_type":"markdown","metadata":{},"source":["Putting it all together in a function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBpK958v7JIP"},"outputs":[],"source":["# Generates an example library for a client based on their profile and scenario\n","def create_example_library(row, scenario):\n","    profile_no_name = profile_as_string(row, display_name=False)\n","    client_gender = determine_gender(row['naam'])\n","\n","    # Invoke the example library chain to get the keywords to search for example notes relevant to this client\n","    keywords = chain_keywords.invoke({\"profile\": profile_no_name, \"scenario\": scenario})\n","    example_notes = get_example_notes(keywords=keywords,retriever=retriever)\n","    example_library = filter_examples_by_gender(texts=example_notes, gender_to_keep=client_gender)\n","\n","    return example_library\n","\n","if VERBOSE:\n","    example_library = create_example_library(test_client, scenario=scenario_as_string(test_client,month_no=1))\n","    sampled_examples_as_string = sample_examples_as_string(example_library=example_library, num_items=3)\n","    print(SEP_LINE)\n","    print(sampled_examples_as_string)"]},{"cell_type":"markdown","metadata":{},"source":["## Setting up the summary memory"]},{"cell_type":"markdown","metadata":{},"source":["### Memory prompt & chain"]},{"cell_type":"markdown","metadata":{},"source":["Adding memory is important because it allows the generated care notes to reflect ongoing developments in a client’s condition and care. This ensures that each new set of notes builds on previous information, maintaining continuity in the narrative of the client’s health and daily experiences.\n","\n","I chose to implement memory by using a summary-based approach. This turned out to be more effective than passing the last notes directly, because it provides context through the profile and the summary, maintaining the storyline. Meanwhile, example notes are refreshed each time, preventing the model from becoming repetitive and producing the same structure repeatedly.\n","\n","Initially, a summary is created that includes the client’s profile and the scenario of the first month. As new care notes are generated, this summary is updated to reflect the latest information. This updated summary is then used as the context for generating subsequent notes, ensuring that the model retains and incorporates past details. \n","\n","In the prompt, the model is asked to update the summary based on the previous summary and the newly generated client notes. \n","\n","[todo: a note about the TEMP, for now, I chose to keep it relatively high]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOVeCoY2r3KI"},"outputs":[],"source":["# Template for updating the client summary based on new care notes\n","\n","PT_memory = PromptTemplate(\n","    template = \"\"\"\n","Hieronder staat:\n","1. Het profiel van een client(e) die verblijft op een psychogeriatrische afdeling van het verpleeghuis. \n","2. Een samenvatting van het beloop tot de indexdatum\n","3. Nieuwe zorgrapportages vanaf de indexdatum\n","\n","PROFIEL:\n","{profile}\n","\n","SAMENVATTING BELOOP TOT INDEXDATUM:\n","{summary}\n","\n","NIEUWE RAPPORTAGES:\n","{new_notes}\n","\n","Schrijf in één alinea een nieuwe samenvatting van het beloop. Neem belangrijke gebeurtenissen en zorgvraag uit de eerdere samenvatting over en vul aan met belangrijke gebeurtenissen en zorgvraag uit de rapportages. Neem de gegevens uit het profiel niet over in de samenvatting.\n","\n","In het antwoord dient uitsluitend de samenvatting van het beloop te staan, zonder aanvullende tekst.\n","\"\"\",\n","    input_variables=[\"profile\", \"summary\", \"new_notes\"],\n",")\n","\n","if VERBOSE:\n","    # Since we don't have any notes yet we'll be using example notes as new_notes\n","    test_new_notes = sample_examples_as_string(example_library,9)\n","    P_memory = PT_memory.format(profile=profile_as_string(test_client),\n","                                summary=scenario_as_string(test_client, month_no=1), \n","                                new_notes=test_new_notes)\n","    print(P_memory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NVUKg7vC5_F8"},"outputs":[],"source":["chain_memory = PT_memory | model\n","\n","if VERBOSE:\n","    updated_summary = chain_memory.invoke({\"profile\": profile_as_string(test_client),\n","                                           \"summary\": scenario_as_string(test_client, month_no=1), \n","                                           \"new_notes\": test_new_notes})\n","    test_summary_m1 = updated_summary.content\n","    pprint(test_summary_m1)"]},{"cell_type":"markdown","metadata":{},"source":["## Generating client notes"]},{"cell_type":"markdown","metadata":{"id":"vWIt5YIZnVSw"},"source":["### Note generation prompts & chain"]},{"cell_type":"markdown","metadata":{},"source":["Our goal is populate the client record by generating care notes reflecting the client profile and describing the scenario. \n","In practice, the number and length of notes per day vary based on clinical circumstances. Stable clients typically have fewer and shorter notes than ill or agitated clients. (I might add this functionality in the future.) Currently, I chose to generate three notes per day. Through trial and error, I found that the model can reliably generate nine notes per prompt. \n","Having a scenario-twist every 3 days is not very realistic. I have scenario descriptions per 'month'. To populate a client record for an entire month, I could decide to break down the monthly scenario into smaller segments that fit the three-day prompt structure. I chose, however, to give the model the scenario in the first iteration and allowing it some creative freedom to build upon it, relying on the summaries to maintain continuity and build upon previous notes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if VERBOSE:\n","    # Let's study the scenario\n","    test_client_id = test_client['client_id']\n","    df_client_scenarios = df_scenarios.loc[df_scenarios['client_id'] == test_client_id, ['journey', 'month']]  \n","    counter = 1\n","    for i, r in df_client_scenarios.iterrows():\n","        print(str(counter) + ' ' + r['journey'])\n","        counter = counter + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDOze-TcewR1"},"outputs":[],"source":["# Template for generating care notes \n","PT_get_notes = PromptTemplate(\n","    template=\"\"\"Jouw taak als AI is om zorgrapportages te schrijven van een fictieve client die verblijft op een psychogeriatrische afdeling van een verpleeghuis.\n","Hieronder staat:\n","- Het profiel van de client. \n","- Een samenvatting van het beloop\n","- Het scenario van de rapportages die je moet schrijven\n","\n","Voorbeeld rapportages:\n","- Dhr. zijn haar gewassen en zijn baard geschoren.\n","- Inco van mw, was verzadigd vanmorgen en bed was nat.\n","{examples}\n","\n","PROFIEL:\n","{profile}\n","\n","SAMENVATTING BELOOP TOT HEDEN:\n","{summary}\n","\n","Gebruik een informele, menselijke stijl. Gebruik relatief eenvoudige taal en vermijd termen als 'cruciaal'.\n","Varieer met de zinsopbouw en stijl. Omschrijf de zorg, zonder het profiel letterlijk te herhalen. Vermijd het noemen van de naam.\n","\n","Schrijf rapportages voor drie dagen. Per dag worden drie rapportages geschreven, dus er zijn 9 rapportages totaal.\n","\n","SCENARIO voor de rapportages die je moet schrijven:\n","{scenario}\n","\n","{format_instructions}\n","\"\"\",\n","    input_variables=[\"examples\", \"profile\", \"summary\", \"scenario\"],\n","    partial_variables={\"format_instructions\": pyd_parser.get_format_instructions()},\n",")\n","\n","if VERBOSE:\n","    P_get_notes = PT_get_notes.format(\n","        examples = sample_examples_as_string(example_library, num_items=3), \n","        profile = profile_as_string(test_client),\n","        # Since we don't have a summary for the first round, we use the scenario for both summary and scenario\n","        summary = scenario_as_string(test_client, 1), \n","        scenario = scenario_as_string(test_client, 1)\n","        )\n","    print(P_get_notes)"]},{"cell_type":"markdown","metadata":{},"source":["Now we create a chain. The output of the chain is a structured list of (nine) care notes for a client, encapsulated in an object called CareNotes. This object contains an attribute named notes, which is a list of individual CareNote entries. Each CareNote entry includes three pieces of information(dag, tijd, rapportage)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a chain of operations: prompt template -> model -> output parser\n","chain_get_notes = PT_get_notes | model | pyd_parser\n","\n","if VERBOSE:\n","    test_notes = chain_get_notes.invoke({\"examples\": sampled_examples_as_string, \n","                                         \"profile\": profile_as_string(test_client),\n","                                         \"summary\": scenario_as_string(test_client, month_no=1), \n","                                         \"scenario\": scenario_as_string(test_client, month_no=1)})\n","\n","    print('***The parsed result of model:')\n","    print(test_notes)\n","\n","    print('\\n***And these are the individual notes')\n","    for note in test_notes.notes:\n","        print(note)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function formats the notes and returns them as a string for display\n","def notes_as_string(notes, simple_bulleted=True):\n","    note_strings = []\n","    for note in notes:\n","        if simple_bulleted:\n","            note_strings.append(f\"- {note.rapportage}\")\n","        else:\n","            note_strings.append(f\"Dag {note.dag} ({note.tijd}): {note.rapportage}\")\n","    return \"\\n\".join(note_strings)\n","\n","if VERBOSE:\n","    print(notes_as_string(test_notes.notes, simple_bulleted=False))\n","    test_notes_m1 = notes_as_string(test_notes.notes)\n","    print(SEP_LINE)\n","    print(test_notes_m1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Seeing some iterations explicitly written out can make the flow of the process clearer, especially when tracking the sequence of actions and understanding the logic at each step. \n","if VERBOSE:\n","    print('PROFILE')\n","    print(profile_as_string(test_client))\n","    print('\\nSCENARIO: '+ scenario_as_string(test_client,month_no=1))\n","    print('\\nNOTES')\n","    print(test_notes_m1)\n","\n","    # Now have the model create a new summary \n","    updated_summary = chain_memory.invoke({\"profile\": profile_as_string(test_client),\n","                                           # Initially, there is no summary\n","                                           \"summary\": scenario_as_string(test_client, month_no=1), \n","                                           \"new_notes\": test_notes_m1})\n","    test_summary_m1 = updated_summary.content\n","    print('\\nSUMMARY')\n","    pprint(test_summary_m1)\n","\n","    # And again some notes\n","    test_notes = chain_get_notes.invoke({\"examples\": sample_examples_as_string(example_library, 3), \n","                                         \"profile\": profile_as_string(test_client),\n","                                         \"summary\": test_summary_m1, \n","                                         \"scenario\": \"Bouw voort op de gegevens uit het Profiel en het Beloop\"})\n","\n","    test_notes_m2 = notes_as_string(test_notes.notes)\n","    print('\\nSCENARIO: '+ \"Bouw voort op de gegevens uit het Profiel en het Beloop\")\n","    print('\\nNOTES')\n","    print(test_notes_m2)\n","\n","    # a new summary \n","    updated_summary = chain_memory.invoke({\"profile\": profile_as_string(test_client),\n","                                           \"summary\": test_summary_m1, \n","                                           \"new_notes\": test_notes_m2})\n","    test_summary_m2 = updated_summary.content\n","    print('\\nSUMMARY')\n","    pprint(test_summary_m2)\n","\n","    # And again some notes\n","    test_notes = chain_get_notes.invoke({\"examples\": sample_examples_as_string(example_library, 3), \n","                                         \"profile\": profile_as_string(test_client),\n","                                         \"summary\": test_summary_m2, \n","                                         \"scenario\": scenario_as_string(test_client, month_no=2)})\n","\n","    test_notes_m3 = notes_as_string(test_notes.notes)\n","    print('\\nSCENARIO: '+ scenario_as_string(test_client,month_no=2))\n","    print('\\nNOTES')\n","    print(test_notes_m3)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Fuctions to populate the client records"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Generate care notes for a client over a specified number of iterations and update the client summary\n","def generate_care_notes(summary_list, notes_list, profile_row, month_no, example_library, num_iterations=5, num_examples=3):  \n","    \"\"\"\n","    Returns:\n","    - Updated list of summaries.\n","    - Updated list of care notes.\n","    \"\"\"\n","    profile = profile_as_string(profile_row)\n","    scenario = scenario_as_string(profile_row, month_no=month_no)\n","    client_id = profile_row['client_id']\n","    summary = summary_list[-1]\n","\n","    for i in range(num_iterations):\n","        iteration = i + 1\n","        try:\n","            print(f'Iteration {iteration}')\n","            if iteration > 1:\n","                # Update the scenario to let the model build upon the scenario\n","                scenario = \"Bouw voort op de gegevens uit het Profiel en het Beloop.\"\n","\n","            # Sample examples from the example library\n","            examples = sample_examples_as_string(example_library, num_examples)\n","\n","            # Generate care notes using the model and the example library\n","            # There are frequent 'Invalid json output' errors. In that case, try again\n","            try:\n","                result_notes = chain_get_notes.invoke({\n","                    \"examples\": examples,\n","                    \"profile\": profile,\n","                    \"summary\": summary,\n","                    \"scenario\": scenario\n","                })\n","            except Exception as e:\n","                # Try once more in case of failure\n","                print(f\"Error in iteration {iteration}, retrying: {e}\")\n","                result_notes = chain_get_notes.invoke({\n","                    \"examples\": examples,\n","                    \"profile\": profile,\n","                    \"summary\": summary,\n","                    \"scenario\": scenario\n","                })\n","                print(\"Retry successful\")\n","\n","            # Update the summary based on the new care notes\n","            result_memory = chain_memory.invoke({\n","                 \"profile\": profile,\n","                 \"summary\": summary,\n","                 \"new_notes\": notes_as_string(result_notes.notes)\n","            })\n","\n","            # Add generated notes to the notes list\n","            for note in result_notes.notes:\n","                notes_list.append({\n","                    \"client_id\": client_id,\n","                    \"month\": month_no,\n","                    \"iteration\": iteration,\n","                    \"dag\": note.dag,\n","                    \"tijd\": note.tijd,\n","                    \"rapportage\": note.rapportage,\n","                })\n","\n","            # add_notes_to_list(result_notes.notes, notes_list, client_id, month_no, iteration)\n","\n","            # Update the memory with new notes and generate a new summary\n","            summary = result_memory.content\n","\n","            # Add the updated summary to the summary list \n","            summary_list.append({\n","                \"client_id\": client_id,\n","                \"month\": month_no,\n","                \"iteration\": iteration,\n","                \"summary\": summary,\n","            })\n","\n","        except Exception as e:\n","            print(f\"Error in iteration {iteration}: {e}\")\n","            continue\n","\n","    return summary_list, notes_list\n","\n","if VERBOSE:\n","    notes_list = []\n","    summary_list = []\n","    summary_list.append({\n","        \"client_id\": test_client['client_id'],\n","        \"month\": 0,\n","        \"iteration\": 0,\n","        \"summary\": scenario_as_string(test_client, month_no=1),\n","        })\n","\n","    summary_list, notes_list = generate_care_notes(\n","        summary_list=summary_list, \n","        notes_list=notes_list, \n","        profile_row=test_client, \n","        example_library=example_library,\n","        month_no=1,\n","        num_iterations=1,\n","        num_examples=3)\n","    \n","    for cs in summary_list:\n","        print(cs)\n","    print(100*'-')\n","    for n in notes_list:\n","        print(n)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Next, let's have a look at the generation of care notes and summaries for a single client. We need to process each client’s data individually. This involves iterating through their associated scenarios and generating relevant notes. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Processe a single client to generate care notes and summaries.\n","def process_client(profile_row, df_scenarios, num_iterations=5, num_examples=3):\n","    all_notes_list = []\n","    all_summaries_list = []\n","\n","    try:\n","        with get_openai_callback() as cb:\n","            print(f\"Processing client: {profile_row['naam']}\")\n","\n","            summary_list = []\n","            notes_list = []\n","\n","            client_id = profile_row['client_id']\n","            # As initial summary, we take the scenario of the first month\n","            summary_list.append({\n","                \"client_id\": profile_row['client_id'],\n","                \"month\": 0,\n","                \"iteration\": 0,\n","                \"summary\": scenario_as_string(profile_row=profile_row, month_no=1),\n","                })\n","\n","            # Select the scenario rows for the client\n","            df_client_scenarios = df_scenarios.loc[df_scenarios['client_id'] == client_id, ['journey', 'month']]  \n","\n","            num_months = len(df_client_scenarios)\n","\n","            month_no = 1    \n","            for i, month_scenario in df_client_scenarios.iterrows():  \n","                scenario = scenario_as_string(profile_row, month_no)\n","                example_library = create_example_library(profile_row, scenario)\n","\n","                print(f'Generating notes for month: {month_no} of {num_months} for client {client_id}')\n","                summary_list, notes_list = generate_care_notes(\n","                    summary_list=summary_list,\n","                    notes_list=notes_list, \n","                    profile_row=profile_row,\n","                    month_no=month_no,\n","                    example_library=example_library,\n","                    num_iterations=num_iterations,\n","                    num_examples=num_examples,\n","                    )\n","                month_no += 1\n","\n","            # Add client_id to notes and summaries\n","            for note in notes_list:\n","                note['client_id'] = client_id\n","            for summary in summary_list:\n","                all_summaries_list.append({'client_id': client_id, 'summary': summary, 'month': month_no})  \n","\n","            all_notes_list.extend(notes_list)\n","            print(cb)\n","\n","    except Exception as e:\n","        print(f\"Error processing client {profile_row['naam']}: {e}\")\n","\n","    return all_notes_list, all_summaries_list\n","\n","if VERBOSE:\n","    notes_list, summaries_list = process_client(profile_row=test_client, df_scenarios=df_scenarios, num_iterations=2, num_examples=3)\n","    for cs in summaries_list:\n","        print(cs)\n","\n","    for n in notes_list:\n","        print(n)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Iterate through all clients, processes each one, and saves the generated notes and summaries to CSV files.\n","def process_clients(df_profiles, df_scenarios):\n","    all_notes_list = []\n","    all_summaries_list = []\n","\n","    for idx, row in df_profiles.iterrows():\n","        try:\n","            notes, summaries = process_client(row, df_scenarios)\n","            all_notes_list.extend(notes)\n","            all_summaries_list.extend(summaries)\n","\n","            df_notes = pd.DataFrame(all_notes_list)\n","            df_summaries = pd.DataFrame(all_summaries_list)\n","\n","            # save after each client to prevent having to start over in case of an error\n","            df_notes.to_csv(PATH_NOTES, index=False)\n","            df_summaries.to_csv(PATH_SUMMARIES, index=False)\n","        except Exception as e:\n","            print(f\"Error processing client: {e}\")\n","\n","process_clients(df_profiles=df_profiles, df_scenarios=df_scenarios)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_dag_counter(df):\n","    \"\"\"\n","    This function updates the 'dag' column in df such that it maintains a running counter per client and per month.\n","    The counter starts at 1 and increments by 1 each time the 'dag' value changes. The counter resets to 1 for each new client and month.\n","    \"\"\"\n","    # Add a column to shift 'dag' values by one row within each group of client_id and month\n","    df['dag_shift'] = df.groupby(['client_id', 'month'])['dag'].shift(1)\n","    # Create a column indicating if 'dag' has changed compared to the previous row\n","    df['dag_changed'] = (df['dag'] != df['dag_shift']).astype(int)\n","    # Create a column indicating the start of a new group (client_id and month)\n","    df['group_changed'] = df.groupby(['client_id', 'month']).cumcount() == 0\n","    \n","    # Update 'group_changed' to be False if 'dag_shift' is NaN\n","    df['group_changed'] = df['group_changed'] & df['dag_shift'].notna()\n","    # Create the counter ('teller') by cumulatively summing 'dag_changed' within each group and adding 'group_changed'\n","    df['dag'] = df.groupby(['client_id', 'month'])['dag_changed'].cumsum() + df['group_changed']\n","    \n","    # Remove the temporary columns used for calculations\n","    df.drop(columns=['dag_shift', 'dag_changed', 'group_changed'], inplace=True)\n","    \n","    return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfn = pd.read_csv(PATH_NOTES)\n","dfn = update_dag_counter(dfn)\n","dfn.to_csv(PATH_NOTES, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","private_outputs":true,"provenance":[{"file_id":"1Y3uhnFPcRHPE4XX5LIKgprOHkWIMwG5R","timestamp":1717916190551}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
