{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_3EzSPkhCZD"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/notebooks/100_note_generation/150_CleanUpNursingHome.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipdYvH-RuXl7"
      },
      "source": [
        "# GenCare AI: Concat and clean data\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:** 2024-09-02  \n",
        "**Updated:** 2024-10-10  \n",
        "**Version:** 2.0\n",
        "\n",
        "### Description\n",
        "This notebook consolidates and cleans client data, scenarios, and care records from different wards. It combines data from CSV files and processes it to ensure consistency across all wards. The notebook restructures client IDs, adjusts the day numbering, and assigns proper timestamps to each care note. Finally, it prepares three datasets: clients, scenarios, and records, which can be used for further analysis or uploaded to platforms like Hugging Face for broader use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhtBxmkAncAM"
      },
      "outputs": [],
      "source": [
        "!pip install GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "        !pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nx_U5CkEmsRR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WFr58E4qm92u"
      },
      "outputs": [],
      "source": [
        "care_home = 'Gardenia'\n",
        "wards = ['Dahlia', 'Magnolia', 'Iris', 'Crocus']\n",
        "\n",
        "fn_clients_df = setup.get_file_path(f'data/gcai_{care_home}_clients.csv')\n",
        "fn_scenarios_df = setup.get_file_path(f'data/gcai_{care_home}_scenarios.csv')\n",
        "fn_records_df = setup.get_file_path(f'data/gcai_{care_home}_records.csv')\n",
        "\n",
        "hf_repo_name = \"ekrombouts/\" + care_home"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IXfYpzIqhCZK"
      },
      "outputs": [],
      "source": [
        "def concatenate_files(wards, file_prefix):\n",
        "    df_list = []\n",
        "\n",
        "    # Loop through each ward to find and read the corresponding file\n",
        "    for ward in wards:\n",
        "        file_name = setup.get_file_path(f'data/{file_prefix}_{ward}.csv')\n",
        "\n",
        "        # Check if the file exists\n",
        "        if os.path.exists(file_name):\n",
        "            df = pd.read_csv(file_name)\n",
        "            df['ward'] = ward  # Add a column to indicate the ward\n",
        "            df_list.append(df)\n",
        "        else:\n",
        "            print(f\"Warning: File {file_name} does not exist and will be skipped.\")\n",
        "\n",
        "    if df_list:\n",
        "        concatenated_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "        # Reorder columns to place 'ward' as the first column\n",
        "        columns = ['ward'] + [col for col in concatenated_df.columns if col != 'ward']\n",
        "        concatenated_df = concatenated_df[columns]\n",
        "\n",
        "        return concatenated_df\n",
        "    else:\n",
        "        print(\"No files to concatenate.\")\n",
        "        return pd.DataFrame()  # Return an empty df if no files were found\n",
        "\n",
        "df_clients = concatenate_files(wards, 'gcai_client_profiles')\n",
        "df_scenarios = concatenate_files(wards, 'gcai_client_scenarios')\n",
        "df_records = concatenate_files(wards, 'gcai_client_notes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O_bYWCuMtP8l"
      },
      "outputs": [],
      "source": [
        "def adjust_client_id(df):\n",
        "    # Adjust 'client_id' to make it unique\n",
        "    df['client_id'] = df['ward'].str[:3].str.lower() + df['client_id'].astype(str).str.zfill(3)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JXkumiBZhCZJ"
      },
      "outputs": [],
      "source": [
        "def update_dayno(df):\n",
        "    # Sort the dataframe by client_id, weekno, dag, and tijd to ensure correct order\n",
        "    df = df.sort_values(['client_id', 'weekno', 'dag', 'tijd'])\n",
        "\n",
        "    # Define a function to apply to each client_id group\n",
        "    def assign_dayno(group):\n",
        "        group = group.copy()\n",
        "        # Create a boolean column that is True when 'dag' changes\n",
        "        group['dag_change'] = group['dag'] != group['dag'].shift()\n",
        "        # Cumulatively sum the 'dag_change' to get the 'dagnummer'\n",
        "        group['dagnummer'] = group['dag_change'].cumsum()\n",
        "        # Adjust so that dagnummer starts at 1\n",
        "        group['dagnummer'] = group['dagnummer'] - group['dagnummer'].min() + 1\n",
        "        return group\n",
        "\n",
        "    # Apply the function to each group\n",
        "    df = df.groupby('client_id', group_keys=False).apply(assign_dayno)\n",
        "    # Remove the 'dag_change' column as it is no longer needed\n",
        "    df = df.drop(columns=['dag_change'])\n",
        "    # Reset the index if necessary\n",
        "    df = df.reset_index(drop=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eDrhE58wuGE"
      },
      "outputs": [],
      "source": [
        "df_clients = adjust_client_id(df_clients)\n",
        "df_scenarios = adjust_client_id(df_scenarios)\n",
        "df_records = adjust_client_id(df_records)\n",
        "df_records = update_dayno(df_records)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5sMqmJOxivg"
      },
      "outputs": [],
      "source": [
        "df_scenarios.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l5OAYlchhCZK"
      },
      "outputs": [],
      "source": [
        "# Function to process client data: Assigns unique ID to clients and merges with scenario data\n",
        "def process_clients(df_clients, df_scenarios):\n",
        "    df_clients = (df_clients\n",
        "                  .merge(df_scenarios[['ward', 'client_id', 'complications', 'num_weeks']].drop_duplicates(),\n",
        "                         on=['ward', 'client_id'], how='left'))\n",
        "    return df_clients\n",
        "\n",
        "df_clients = process_clients(df_clients, df_scenarios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vuDbfAnyIJq"
      },
      "outputs": [],
      "source": [
        "df_scenarios.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LO0I3_TjhCZL"
      },
      "outputs": [],
      "source": [
        "# Function to process scenarios data\n",
        "def process_scenarios(df_scenarios, df_clients):\n",
        "    df_scenarios = (df_scenarios\n",
        "                    # Complications and num_months have been added to the clients df\n",
        "                    .drop(columns=['complications', 'num_weeks'])\n",
        "                    # Get the unique client ID\n",
        "                    .merge(df_clients[['ward', 'client_id']], on=['client_id'], how='left')\n",
        "                    # Extract the month number from the string\n",
        "                    .rename(columns={'events_description': 'scenario'})\n",
        "                    [['client_id', 'week', 'scenario']])\n",
        "    return df_scenarios\n",
        "\n",
        "df_scenarios = process_scenarios(df_scenarios, df_clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lx5hLlIo0cgy"
      },
      "outputs": [],
      "source": [
        "def process_records(df_records, df_clients):\n",
        "    # Generate a random start date for each client_id\n",
        "    unique_client_ids = df_clients['client_id'].unique()\n",
        "    start_dates = {client_id: datetime(2022, 1, 1) + timedelta(days=random.randint(0, 365)) for client_id in unique_client_ids}\n",
        "\n",
        "    # Calculate the maximum 'dag' (day) value for each 'client_id'\n",
        "    max_days_per_client_id = df_records.groupby('client_id')['dag'].max().to_dict()\n",
        "\n",
        "    # Function to calculate the date using the start_date for each client_id and max 'dag' value\n",
        "    def calculate_datetime(row):\n",
        "        max_day = max_days_per_client_id.get(row['client_id'], 15)  # Use the max 'dag' value or default to 15\n",
        "        start_date = start_dates[row['client_id']]  # Get the start date for the specific client_id\n",
        "        # Combine date and time\n",
        "        base_date = start_date + timedelta(days=(row['weekno'] - 1) * max_day + (row['dag'] - 1))\n",
        "        # Keep only digits in the time string\n",
        "        tijd_str = str(row['tijd'])\n",
        "        time_digits = ''.join(filter(str.isdigit, tijd_str))\n",
        "        # Handle missing or invalid time\n",
        "        if len(time_digits) == 3:\n",
        "            time_digits = '0' + time_digits  # Pad with zero if time is of form '800' instead of '0800'\n",
        "        if len(time_digits) != 4:\n",
        "            # Default to midnight if time is invalid\n",
        "            time_delta = datetime.min.time()\n",
        "        else:\n",
        "            # Convert the cleaned time string to a time object using the '%H%M' format\n",
        "            time_dt = pd.to_datetime(time_digits, format='%H%M', errors='coerce')\n",
        "            if pd.isnull(time_dt):\n",
        "                # Default to midnight if parsing fails\n",
        "                time_delta = datetime.min.time()\n",
        "            else:\n",
        "                time_delta = time_dt.time()\n",
        "        return datetime.combine(base_date, time_delta)\n",
        "\n",
        "    # Apply the datetime calculation to each record and update the DataFrame\n",
        "    df_records = (df_records\n",
        "                  .assign(datetime=lambda df: df.apply(\n",
        "                      lambda row: calculate_datetime(row), axis=1))\n",
        "                  .rename(columns={'rapportage': 'note'})\n",
        "                  [['client_id', 'datetime', 'note']])\n",
        "\n",
        "    return df_records\n",
        "\n",
        "df_records = process_records(df_records, df_clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Fe7KGUtomwhj"
      },
      "outputs": [],
      "source": [
        "def rename_client_columns(df_clients):\n",
        "    # Rename and reorder columns for df_clients.\n",
        "    df_clients = (df_clients\n",
        "                  .rename(columns={\n",
        "                      'naam': 'name',\n",
        "                      'type_dementie': 'dementia_type',\n",
        "                      'somatiek': 'physical',\n",
        "                      'adl': 'adl',\n",
        "                      'mobiliteit': 'mobility',\n",
        "                      'gedrag': 'behavior',\n",
        "                  })\n",
        "                  [['client_id', 'ward', 'name', 'dementia_type', 'physical', 'adl',\n",
        "                    'mobility', 'behavior', 'complications', 'num_weeks']])\n",
        "    return df_clients\n",
        "\n",
        "df_clients = rename_client_columns(df_clients)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OKlQYykIhCZN"
      },
      "outputs": [],
      "source": [
        "# Save final processed dataframes\n",
        "df_clients.to_csv(fn_clients_df, index=False)\n",
        "df_scenarios.to_csv(fn_scenarios_df, index=False)\n",
        "df_records.to_csv(fn_records_df, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBy0lXlNhCZN"
      },
      "outputs": [],
      "source": [
        "# # Function to convert DataFrames to Hugging Face Datasets and push to hub\n",
        "# def push_dataset_to_hub(df, dataset_name, hf_repo_name):\n",
        "#     dataset = Dataset.from_pandas(df)\n",
        "#     dataset.push_to_hub(f\"{hf_repo_name}_{dataset_name}\", private=True)\n",
        "\n",
        "# push_dataset_to_hub(df_records, \"records\", hf_repo_name)\n",
        "# push_dataset_to_hub(df_scenarios, \"scenarios\", hf_repo_name)\n",
        "# push_dataset_to_hub(df_clients, \"clients\", hf_repo_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhJz989mhCZN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gcai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
