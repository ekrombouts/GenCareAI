{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/main/drafts/300_ClassicNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Determines the current environment (Google Colab or local)\n",
        "def check_environment():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return \"Google Colab\"\n",
        "    except ImportError:\n",
        "        pass\n",
        "\n",
        "    return \"Local Environment\""
      ],
      "metadata": {
        "id": "byZHjemJIuIn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = check_environment()\n",
        "\n",
        "if env == \"Google Colab\":\n",
        "    print(\"Running in Google Colab\")\n",
        "    # !pip install -q datasets\n",
        "    !python -m spacy download nl_core_news_md\n",
        "    from google.colab import drive, userdata\n",
        "    drive.mount('/content/drive')\n",
        "    DATA_DIR = '/content/drive/My Drive/Colab Notebooks/GenCareAI/data'\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "else:\n",
        "    print(\"Running in Local Environment\")\n",
        "    DATA_DIR = '../data'\n",
        "    # !python -m spacy download nl_core_news_md\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "    HF_TOKEN = os.getenv('HF_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNet4e5wIwaE",
        "outputId": "9fb96f42-13fd-457d-d122-84862e9dcd7f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab\n",
            "Collecting nl-core-news-md==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/nl_core_news_md-3.7.0/nl_core_news_md-3.7.0-py3-none-any.whl (42.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from nl-core-news-md==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.7.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->nl-core-news-md==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('nl_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_notes = load_dataset('ekrombouts/dutch_nursing_home_notes', token=HF_TOKEN)\n",
        "df_notes = pd.DataFrame(df_notes['train'])\n"
      ],
      "metadata": {
        "id": "dyfngZNsISkc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialiseer spaCy\n",
        "nlp = spacy.load('nl_core_news_md')"
      ],
      "metadata": {
        "id": "qbA7V2x9Ikcf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functie voor het voorverwerken van de tekst\n",
        "def preprocess_text(text):\n",
        "    # Controleer op nan-waarden\n",
        "    if pd.isnull(text):\n",
        "        return ''\n",
        "\n",
        "    # Verwerk de tekst met spaCy\n",
        "    doc = nlp(text.lower())\n",
        "\n",
        "    # Selecteer de lemmata van de tokens met bepaalde PoS-tags\n",
        "    lemmatized_text = ' '.join([token.lemma_ for token in doc if token.pos_ in {'NOUN', 'VERB', 'ADJ', 'ADV'}])\n",
        "\n",
        "    return lemmatized_text"
      ],
      "metadata": {
        "id": "iziGrtnnQyyi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aap = df_notes['note'][0]\n",
        "print(aap)\n",
        "print(preprocess_text(aap))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY29Kj4uR2sO",
        "outputId": "d3bacf0e-97d9-4793-e176-4b05a7e7984c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mevrouw heeft vanmorgen hulp gekregen bij het aankleden en klaarmaken voor de dag.\n",
            "mevrouw vanmorgen hulp krijgen aankleden klaarmaken dag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paralleliseer de tekstvoorverwerking met een progressbar\n",
        "def parallel_preprocess_texts(texts, max_workers=4):\n",
        "    results = [None] * len(texts)\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = {executor.submit(preprocess_text, text): i for i, text in enumerate(texts)}\n",
        "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "            index = futures[future]\n",
        "            results[index] = future.result()\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "Cwd6F7hbT9SG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pas de functie toe op de kolom 'note'\n",
        "# tqdm.pandas()\n",
        "# df_notes['processed_note'] = df_notes['note'].progress_apply(preprocess_text)\n",
        "df_notes['processed_note'] = parallel_preprocess_texts(df_notes['note'].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ilDkYYdRwb5",
        "outputId": "4832cea5-3ed7-4699-9a1b-9df52b82e1be"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 43283/43283 [07:36<00:00, 94.89it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Controleer het resultaat\n",
        "print(df_notes[['note', 'processed_note']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCcWZj8gSlX2",
        "outputId": "b3128737-9bea-4127-aaf4-6a3a2b22e542"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                note  \\\n",
            "0  Mevrouw heeft vanmorgen hulp gekregen bij het ...   \n",
            "1  Meneer is gedoucht en zijn gebitsprothese is s...   \n",
            "2  Tijdens het ochtendritueel is mw. geholpen met...   \n",
            "3  Dhr. is vanochtend gewassen en geholpen met aa...   \n",
            "4  Na het ongelukje is mw. verschoond en is haar ...   \n",
            "\n",
            "                                      processed_note  \n",
            "0  mevrouw vanmorgen hulp krijgen aankleden klaar...  \n",
            "1         meneer douchten gebitsprothese schoonmaken  \n",
            "2  ochtendritueel helpen tand poetsen klaargemaak...  \n",
            "3                  vanochtend wassen helpen aanklead  \n",
            "4                      ongelukje verschoond gedoucht  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Maak een CountVectorizer object\n",
        "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='dutch')\n",
        "\n",
        "# Pas de vectorizer toe op de processed notes\n",
        "X = vectorizer.fit_transform(df_notes['processed_note'])\n",
        "\n",
        "# Maak een LDA object aan\n",
        "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
        "\n",
        "# Pas LDA toe op de getransformeerde data\n",
        "lda.fit(X)\n",
        "\n",
        "# Functie om de top woorden per topic weer te geven\n",
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic #{topic_idx + 1}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
        "    print()\n",
        "\n",
        "# Print de top woorden per topic\n",
        "n_top_words = 10\n",
        "tf_feature_names = vectorizer.get_feature_names_out()\n",
        "print_top_words(lda, tf_feature_names, n_top_words)"
      ],
      "metadata": {
        "id": "tf9EseibV6Zf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}